---
title: "Trabalho MLG"
subtitle: ""
author: "Eliana Cardoso Gon√ßalves e Sophia Araujo de Moraes"
date: "08/26/2024"
date-format: short # formata√ß√£o dd/mm/aaaa
lang: pt # linguagem
toc: true # √≠ndice
number-sections: true
fig-cap-location: top # localiza√ß√£o t√≠tulo figura 
geometry:
  - top=3cm
  - left=3cm
  - right=2cm
  - bottom=2cm
tbl-cap-location: top
df-print: kable # sa√≠da dos data frames serem kable
fig-width: 10
fig-height: 4
format: 
  html:
    self-contained: true # tornar o html compartilh√°vel
    theme: flatly
  pdf: 
    documentclass: scrreprt
    margin: 1in
  docx: default
editor:
  markdown:
    wrap: 72
editor_options:
  chunk_output_type: console
output: 
  pdf_document:
    fig_caption: true
    df_print: kable
  word_document:
    fig_caption: true
    df_print: kable
prefer-html: true
execute:
  echo: false
  warning: false
---

```{r}
rm(list = ls())

if(!require(remotes)) install.packages("remotes")
remotes::install_github("fndemarqui/reglin")
```

```{r, include=FALSE}
#install.packages("tinytex")
library(tinytex)
#tinytex::install_tinytex()  # Para instalar uma distribui√ß√£o LaTeX m√≠nima

#install.packages("flextable")
library(flextable)
#install.packages("rmarkdown")
library(rmarkdown)
```

```{r,biblioteca}


if (!require(pacman))(install.packages("pacman"))(require(pacman))
pacman::p_load( kableExtra, corrplot, haven, ggplot2, 
  tidyverse, performance, see, car, 
  knitr, patchwork, summarytools, 
  caret, pROC, dplyr, reglin, dplyr)

```

```{r,diretorio}

source("_src/src.R")

```

# Dados da Penn World Table de 2020

Dois t√≥picos desse estudo (MODELO LINEAR NORMAL e MODELO GAMA
LOG-LINEAR) se concentram em uma amostra de 183 pa√≠ses distintos no ano
de 2014. Os dois modelos foram utilizados para explorar como a for√ßa de
trabalho e o estoque de capital influenciam o PIB, desse modo por meio
de regress√µes lineares m√∫ltiplas, ser√° estimado os coeficientes que
quantificam essas rela√ß√µes, permitindo-nos compreender melhor os
determinantes do crescimento econ√¥mico.

Essa rela√ß√£o pode ser expressa pela seguinte equa√ß√£o:

$$Y=Œ≤0+Œ≤1X1+Œ≤2X2+...+Œ≤pXp+Œµ$$

Onde:

-   $Y$ √© a vari√°vel dependente ( PIB Nacional (Y) em d√≥lares PPP de
    2014).

-   $X1,X2,...,Xp$ s√£o as vari√°veis independentes ( For√ßa de Trabalho
    (L)e o Estoque de Capital (K) em d√≥lares PPP de 2014).

-   $Œ≤1,Œ≤2,...,Œ≤p$ s√£o os coeficientes de regress√£o que representam os
    efeitos das vari√°veis independentes na vari√°vel dependente.

-   $Œµ$ √© o termo de erro, que representa a varia√ß√£o n√£o explicada pelo
    modelo.

Para complementar a an√°lise, √© importante entender como os dois modelos
‚Äî o Modelo Linear Normal e o Modelo Gama Log-Linear ‚Äî foram utilizados
para explorar as rela√ß√µes entre o PIB nacional, a for√ßa de trabalho e o
estoque de capital. Esses modelos oferecem diferentes abordagens para
analisar os dados e podem fornecer insights valiosos sobre os fatores
que impulsionam o crescimento econ√¥mico:

**Modelo Linear Normal**: O Modelo Linear Normal √© uma aplica√ß√£o
cl√°ssica da regress√£o linear m√∫ltipla. Neste contexto, assume-se que a
rela√ß√£o entre as vari√°veis independentes (for√ßa de trabalho e estoque de
capital) e a vari√°vel dependente (PIB) √© linear. Isso significa que cada
incremento em uma vari√°vel independente resulta em um aumento ou
diminui√ß√£o constante na vari√°vel dependente, dependendo do sinal e do
valor dos coeficientes de regress√£o.

Este modelo √© baseado em algumas suposi√ß√µes, como a normalidade dos
res√≠duos, homocedasticidade (ou seja, a vari√¢ncia constante dos
res√≠duos), e a aus√™ncia de multicolinearidade entre as vari√°veis
independentes. Quando essas suposi√ß√µes s√£o satisfeitas, o Modelo Linear
Normal fornece estimativas consistentes e eficientes dos coeficientes de
regress√£o, permitindo uma compreens√£o clara de como cada fator contribui
para o PIB.

**Modelo Gama Log-Linear**: Por outro lado, o Modelo Gama Log-Linear
oferece uma abordagem alternativa, especialmente √∫til quando os dados
n√£o atendem √†s suposi√ß√µes de normalidade e homocedasticidade do modelo
linear. Este modelo √© particularmente apropriado para situa√ß√µes onde a
vari√°vel dependente (PIB) assume valores positivos e pode apresentar uma
distribui√ß√£o assim√©trica, o que √© comum em dados econ√¥micos.

No Modelo Gama Log-Linear, a transforma√ß√£o logar√≠tmica √© aplicada √†
vari√°vel dependente. Isso permite capturar rela√ß√µes n√£o lineares entre o
PIB e as vari√°veis independentes, como a for√ßa de trabalho e o estoque
de capital. A distribui√ß√£o Gama, utilizada nesse modelo, √© adequada para
modelar a vari√°vel dependente em casos onde h√° heterocedasticidade ‚Äî ou
seja, quando a variabilidade dos dados aumenta com o valor previsto.

Essa abordagem √© especialmente √∫til para capturar efeitos
multiplicativos, onde as vari√°veis independentes influenciam a vari√°vel
dependente de forma proporcional, em vez de aditiva. O Modelo Gama
Log-Linear pode, portanto, revelar nuances e complexidades na rela√ß√£o
entre os fatores estudados e o crescimento econ√¥mico que o modelo linear
normal pode n√£o captar.

## Modelo Linear Normal

```{r}
dta = read_dta("_dta/pwt1001.dta")
# filtrando para 2014
dta = dta %>% subset(year == '2014')
```

```{r}
## criando as vari√°veis de interesse
# definindo as vari√°veis
dta$Y = dta$rgdpo
dta$L = dta$emp*dta$hc
dta$K = dta$rnna
# rearranjando colunas
dta = dta %>% relocate(Y, .after = year)
dta = dta %>% relocate(L, .after = Y)
dta = dta %>% relocate(K, .after = K)
# filtrando NAs
df.complete = dta[, c('Y', 'L', 'K')] %>% na.omit()
dta = merge(df.complete, dta, all.x = TRUE)


```

```{r}
#| label: tbl-t1
#| tbl-cap: Tabela Resumo das Vari√°veis Y, L e K.

descr_stats <- descr(dta[, c('Y', 'L', 'K')], 
                     stats = c("mean", "sd", "min", "med", "max"), 
                     transpose = FALSE, 
                     headings = FALSE)

# Convertendo para um dataframe para facilitar a manipula√ß√£o
descr_df <- as.data.frame(descr_stats)

# Adicionando a coluna de Estat√≠sticas
descr_df <- descr_df %>%
  dplyr::select( everything())

# Exibindo a tabela formatada em markdown
library(knitr)
kable(descr_df, format = "markdown")%>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necess√°rio


```

```{r}
#| label: fig-y
#| fig-cap: Histograma PIB Nacional (Y) em d√≥lares PPP de 2014
p <- ggplot(dta, aes(x = Y)) +
  # Histograma
  geom_histogram(aes(y = after_stat(density)), fill = 'lightblue', color = 'black', bins = 10) +
  # Distribui√ß√£o normal (para compara√ß√£o)
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$Y, na.rm = TRUE), sd = sd(dta$Y, na.rm = TRUE))) +
  # Label eixo x
  xlab('Y') +
  # Label eixo y
  ylab('Density') +
  # Tema do plot
  theme(
    # Painel
    panel.background = element_blank(),
    panel.border = element_blank(),
    # Eixos
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )
p
```

Observando o @fig-y e @tbl-t1 , o valor m√≠nimo do PIB √© \$2.569,
enquanto o valor m√°ximo √© significativamente maior, chegando a
\$18.244.220, indicando uma grande varia√ß√£o no PIB entre os pa√≠ses da
amostra.A m√©dia do PIB √© \$769.941, o que √© substancialmente maior que a
mediana de \$123.419, sugerindo que alguns pa√≠ses com PIB muito alto
est√£o puxando a m√©dia para cima. A distribui√ß√£o do PIB √© bastante
assim√©trica, com muitos pa√≠ses tendo PIBs relativamente baixos e poucos
pa√≠ses com PIBs muito altos.

```{r}
#| label: fig-l
#| fig-cap: Histograma For√ßa de Trabalho (L)


p = ggplot(dta, aes(x = L)) +
  # histograma
  geom_histogram(aes(x = L, after_stat(density)), fill = 'lightblue', col = 'black', bins = 10) +
  # dist. normal (p/ compara√ß√£o)
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$L), sd = sd(dta$L))) + 
  # label eixo x
  xlab('L') +
  # label eixo y
  ylab('Density') +
  # tema do plot
  theme(
    # painel
    panel.background = element_blank(),
    panel.border = element_blank(),
    # eixos
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )
p

```

Analisando o @fig-l e a @tbl-t1, a varia√ß√£o da for√ßa de trabalho de
0,2994 a 2.045,91 reflete uma grande disparidade na popula√ß√£o
economicamente ativa entre os pa√≠ses. Com uma m√©dia de 54,60 e uma
mediana de 11,65, a distribui√ß√£o mostra-se assim√©trica, sugerindo a
presen√ßa de pa√≠ses com for√ßas de trabalho extremas, seja pela sua
grandeza ou pequenez em rela√ß√£o √† m√©dia da amostrm alguns pa√≠ses com
pa√≠ses com a for√ßa de trabalho outlier.

```{r}
#| fig-cap: Histograma Estoque de Capital (K) em d√≥lares PPP de 2014)
#| label: fig-k


p = ggplot(dta, aes(x = K)) +
  # histograma
  geom_histogram(aes(x = K, after_stat(density)), fill = 'lightblue', col = 'black', bins = 10) +
  # dist. normal (p/ compara√ß√£o)
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$K), sd = sd(dta$K))) + 
  # label eixo x
  xlab('K') +
  # label eixo y
  ylab('Density') +
  # tema do plot
  theme(
    # painel
    panel.background = element_blank(),
    panel.border = element_blank(),
    # eixos
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )
p

```

Analisando os valores da @tbl-t1 e @fig-k , observamos que o estoque de
capital varia amplamente, de \$7.345 a \$64.118.472, indicando
diferen√ßas significativas no n√≠vel de investimento em capital produtivo
entre os pa√≠ses.

A m√©dia do estoque de capital √© \$3.058.761, consideravelmente maior que
a mediana de \$394.841, o que sugere que alguns pa√≠ses t√™m estoques de
capital extremamente altos que est√£o elevando a m√©dia.

### Resultados

Para garantir a robustez e confiabilidade dos resultados, optamos por
realizar uma transforma√ß√£o log-log nas vari√°veis, considerando que o PIB
Nacional (Y) em d√≥lares PPP de 2014, juntamente com as vari√°veis
independentes "for√ßa de trabalho" e "estoque de capital", n√£o apresentam
uma distribui√ß√£o normal. Essa abordagem vai permitir que aos
pressupostos do modelo normal sejam atendidos e obter resultados mais
consistentes.

Ao aplicar a transforma√ß√£o log-log, estamos ajustando a distribui√ß√£o das
vari√°veis para se adequarem melhor ao modelo, mitigando quaisquer
distor√ß√µes ou vi√©s que possam surgir devido √† falta de normalidade. Isso
nos permite realizar infer√™ncias estat√≠sticas mais confi√°veis e
interpretar os efeitos das vari√°veis independentes sobre o PIB Nacional
de forma mais precisa.

```{r}
# Aplicar transforma√ß√£o logar√≠tmica
dta$log_Y <- log(dta$Y)
dta$log_L <- log(dta$L)
dta$log_K <- log(dta$K)


# Histogramas

# Histograma log do PIB Nacional (log_Y)
p_log_Y <- ggplot(dta, aes(x = log_Y)) +
  geom_histogram(aes(y = after_stat(density)), fill = 'lightblue', color = 'black', bins = 10) +
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$log_Y, na.rm = TRUE), sd = sd(dta$log_Y, na.rm = TRUE)),
                color = 'red', linewidth = 1) +
  xlab('log(Y)') +
  ylab('Density') +
  theme(
    panel.background = element_blank(),
    panel.border = element_blank(),
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )

# Histograma log da For√ßa de Trabalho (log_L)
p_log_L <- ggplot(dta, aes(x = log_L)) +
  geom_histogram(aes(y = after_stat(density)), fill = 'lightblue', color = 'black', bins = 10) +
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$log_L, na.rm = TRUE), sd = sd(dta$log_L, na.rm = TRUE)),
                color = 'red', linewidth = 1) +
  xlab('log(L)') +
  ylab('Density') +
  theme(
    panel.background = element_blank(),
    panel.border = element_blank(),
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )

# Histograma log do Estoque de Capital (log_K)
p_log_K <- ggplot(dta, aes(x = log_K)) +
  geom_histogram(aes(y = after_stat(density)), fill = 'lightblue', color = 'black', bins = 10) +
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$log_K, na.rm = TRUE), sd = sd(dta$log_K, na.rm = TRUE)),
                color = 'red', linewidth = 1) +
  xlab('log(K)') +
  ylab('Density') +
  theme(
    panel.background = element_blank(),
    panel.border = element_blank(),
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )

# Exibir os gr√°ficos
p_log_Y

```

```{r}

p_log_L

```

```{r}

p_log_K

```

Essa estrat√©gia de transforma√ß√£o aumenta a robustez da an√°lise, pois
reduz a influ√™ncia de valores extremos e torna os resultados menos
sens√≠veis a distribui√ß√µes n√£o normais. Portanto, podemos ter maior
confian√ßa nas conclus√µes derivadas do modelo, garantindo uma abordagem
metodol√≥gica s√≥lida e resultados mais confi√°veis para tomada de decis√£o.

A an√°lise macroecon√¥mica √© fundamental para entender o desenvolvimento
econ√¥mico e social dos pa√≠ses. No contexto da contabilidade nacional,
vari√°veis como o Produto Interno Bruto (PIB), a for√ßa de trabalho e o
estoque de capital s√£o essenciais para avaliar a produtividade e o
crescimento econ√¥mico. Este estudo utiliza dados da Penn World Table de
2020 para investigar a rela√ß√£o entre essas vari√°veis.

O PIB nacional (Y), medido em d√≥lares PPC de 2014, √© uma medida
abrangente da atividade econ√¥mica de um pa√≠s. A for√ßa de trabalho (L)
representa o total de pessoas empregadas ou em busca de emprego,
refletindo a capacidade produtiva humana. O estoque de capital (K),
tamb√©m medido em d√≥lares PPC de 2014, indica o valor total dos ativos
produtivos de um pa√≠s, como m√°quinas, edif√≠cios e infraestrutura.

Ao analisar essas vari√°veis, o objetivo √© fornecer insights sobre as
pol√≠ticas econ√¥micas que podem fomentar o crescimento e a produtividade.
Esta investiga√ß√£o pode ajudar formuladores de pol√≠ticas, economistas e
pesquisadores a identificar √°reas-chave para interven√ß√£o e investimento,
promovendo um desenvolvimento econ√¥mico sustent√°vel e inclusivo.

```{r}
interpreta <- function(mod, alpha = 0.05) {
  tab <- summary(mod)
  tabela <- as.data.frame(coef(tab))
  tabela <- cbind(Covariavel = rownames(tabela), tabela)
  tabela <- tabela %>%
    mutate(
      Estima√ß√£o = Estimate,
      Pvalor = `Pr(>|t|)`,
      sig = case_when(
        is.na(`Pr(>|t|)`) ~ " ",
        `Pr(>|t|)` < 0.001 ~ "<0.001***",
         `Pr(>|t|)` <= alpha ~ paste0(" ", format(`Pr(>|t|)`, digits = 3), "*"),
        TRUE ~ paste0(" ", format(`Pr(>|t|)`, digits = 3))
      )
    ) %>%
    dplyr::select( Estima√ß√£o, Pvalor, sig)
  
  return(tabela)
}
```

```{r}
#| label: tbl-t2
#| tbl-cap: Ajuste do Modelo de Regress√£o Log-Normal 

fit = lm(log(Y) ~ log(L) + log(K), data = dta)


fit %>% interpreta()                           
```

Todos os p-valores associados aos coeficientes s√£o muito pequenos
(\<0.001), o que significa que podemos rejeitar a hip√≥tese nula para
todos os coeficientes, ao n√≠vel de 5% de confian√ßa. Isso indica que
tanto a for√ßa de trabalho quanto o estoque de capital t√™m efeitos
significativos no PIB, conforme medido pelo logaritmo.

O coeficiente estimado para log(K) √© 0,70728. Isso significa que, se o
estoque de capital (K) aumentar em 1%, o PIB (Y) aumentar√° em
aproximadamente 0.70728 √ó 100 = 70.728 , mantendo todas as outras
vari√°veis constantes.

O coeficiente estimado para log ‚Å° (L ) √©0.29. Isso significa que, se a
for√ßa de trabalho (L) aumentar em 1%, o PIB (Y) aumentar√° em
aproximadamente 0,29 √ó 100 =29,409, mantendo todas as outras vari√°veis
constantes.

Al√©m disso, o modelo tem um R-quadrado ajustado de aproximadamente 0,96,
o que significa que aproximadamente 95,92% da variabilidade no logaritmo
do PIB pode ser explicada pelas vari√°veis independentes inclu√≠das no
modelo.

Esses resultados sugerem que tanto a for√ßa de trabalho quanto o estoque
de capital t√™m um impacto significativo no PIB, conforme medido pelo
logaritmo.

-   **Hip√≥tese Nula** $(H_0)$: $\alpha + \beta = 1$ A soma dos
    coeficientes √© igual a 1, sugerindo retornos constantes √† escala.
-   **Hip√≥tese Alternativa** $(H_1)$: $\alpha + \beta \neq 1$ A soma dos
    coeficientes n√£o √© igual a 1, sugerindo que n√£o h√° retornos
    constantes √† escala.

```{r}
#| tbl-cap: Teste
#| label: tbl-teste1

# Estimar o modelo de regress√£o log-linear
fit = lm(log(Y) ~ log(L) + log(K), data = dta)

# Carregar o pacote necess√°rio
library(knitr)

# Obter as estimativas de alpha e beta
alpha_hat <- coef(fit)["log(L)"]
beta_hat <- coef(fit)["log(K)"]

# Teste de hip√≥tese
soma_alpha_beta <- alpha_hat + beta_hat
se_alpha_beta <- sqrt(vcov(fit)["log(L)", "log(L)"] + vcov(fit)["log(K)", "log(K)"] + 2 * vcov(fit)["log(L)", "log(K)"])

# Calcular a estat√≠stica t
t_statistic <- (soma_alpha_beta - 1) / se_alpha_beta

# Calcular o valor-p
p_value <- 2 * pt(-abs(t_statistic), df = df.residual(fit))

# Criar uma tabela com os resultados
resultados <- data.frame(
  Estat√≠stica = c("Estimativa de alpha", "Estimativa de beta", "Soma de alpha e beta", "Estat√≠stica t", "Valor-p"),
  Valor = c(alpha_hat, beta_hat, soma_alpha_beta, t_statistic, p_value)
)

# Exibir a tabela
kable(resultados, col.names = c("Estat√≠stica", "Valor"), format = "markdown", digits = 4)%>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necess√°rio


```

Na @tbl-teste1, com teste da Teste $ùêª0 : ùõº + ùõΩ = 1$ contra
$ùêª1 : ùõº + ùõΩ ‚â† 1$, obtivemos um p-valor de aproximadamente 0,943. N√£o
rejeitamos a hip√≥tese nula $H_0$ ao n√≠vel de 5% de signific√¢ncia. Isso
indica que os dados n√£o fornecem evid√™ncias suficientes para concluir
que a soma de $\alpha$ e $\beta$ √© diferente de 1. Em outras palavras, a
suposi√ß√£o de retornos constantes √† escala $\alpha + \beta = 1$ √©
razo√°vel para o ano analisado. Isso sugere que, com base nos dados, um
aumento proporcional igual na for√ßa de trabalho (L) e no capital (K)
resulta em um aumento proporcional na produ√ß√£o (Y), confirmando a
hip√≥tese de retornos constantes √† escala na fun√ß√£o de produ√ß√£o
Cobb-Douglas.

### An√°lise dos Res√≠duos

```{r}
#| label: fig-t3
#| fig-cap: Grafico de An√°lise de res√≠duos 

ggresiduals(fit)
#testResiduals(fit)
```

```{r}
#testResiduals(fit)

# Criando o data frame com os resultados dos testes
test_results <- data.frame(
  Teste = c("Shapiro-Wilk Normality Test", 
            "Non-constant Variance Score Test", 
            "Durbin-Watson Test for Autocorrelated Errors"),
  Estat√≠stica = c("W = 0.96", 
                  "Chisquare = 5.338458", 
                  "D-W Statistic = 2.133801"),
  `p-valor` = c(0.0003379, 0.02086, 0.42))

kable(test_results, caption = "Resultados dos Testes de Res√≠duos") %>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necess√°rio


```

Com base na an√°lise da tabela @fig-t3, podemos concluir o seguinte sobre
o ajuste do modelo de regress√£o:

**Homocedasticidade:** - A vari√¢ncia dos res√≠duos parece ser constante
em toda a faixa dos valores ajustados, o que √© consistente com a
suposi√ß√£o de homocedasticidade na regress√£o linear.

**Normalidade:** - Embora o teste de Shapiro-Wilk sugira que os res√≠duos
n√£o sigam uma distribui√ß√£o normal, desconsiderando caudas pesadas tanto
nos extremos inferiores quanto nos superiores, podemos aproximar que os
res√≠duos est√£o pr√≥ximos de uma distribui√ß√£o normal.

**Independ√™ncia dos Res√≠duos:** - Tanto o teste de Durbin-Watson quanto
a inspe√ß√£o do gr√°fico de res√≠duos versus valores ajustados na tabela
@fig-t3 n√£o fornecem evid√™ncias significativas para rejeitar a hip√≥tese
nula de aus√™ncia de autocorrela√ß√£o positiva ou negativa nos res√≠duos.
Assim, parece que os res√≠duos s√£o independentes entre si.

**Linearidade:** - N√£o h√° um padr√£o claro nos res√≠duos plotados em
rela√ß√£o aos valores ajustados, indicando linearidade entre as vari√°veis
independentes e dependentes.

Portanto, concluirmos que o modelo de regress√£o parece atender √†s
suposi√ß√µes de homocedasticidade, normalidade aproximada dos res√≠duos,
independ√™ncia dos res√≠duos e linearidade entre as vari√°veis.

## Modelo Gama Log-Linear

### Resultados

Utilizamos o mesmo banco de dados do Modelo de Log-Normal.Por meio da
tabela abaixo √© poss√≠vel verificar como foi o ajuste das vari√°veis ao
modelo de gama log-linear:

```{r}
interpreta <- function(mod, alpha = 0.05) {
  tab <- summary(mod)
  tabela <- as.data.frame(coef(tab))
  tabela <- cbind(Covariavel = rownames(tabela), tabela)
  tabela <- tabela %>%
    mutate(
      Estimacao = round(Estimate,4),
      ErroPadrao = round(`Std. Error`,4),
      Pvalor = `Pr(>|t|)`,
      sig = case_when(
        is.na(`Pr(>|t|)`) ~ " ",
        `Pr(>|t|)` < 0.001 ~ "<0.001***",
        `Pr(>|t|)` <= alpha ~ paste0(" ", format(`Pr(>|t|)`, digits = 3), "*"),
        TRUE ~ paste0(" ", format(`Pr(>|t|)`, digits = 3))
      )
    ) %>%
    dplyr::select(Estimacao, ErroPadrao, Pvalor, sig)
  
  return(tabela)
}

```

```{r}
dta = read_dta("_dta/pwt1001.dta")
# filtrando para 2014
dta = dta %>% subset(year == '2014')
```

```{r}
## criando as vari√°veis de interesse
# definindo as vari√°veis
dta$Y = dta$rgdpo
dta$L = dta$emp*dta$hc
dta$K = dta$rnna
# rearranjando colunas
dta = dta %>% relocate(Y, .after = year)
dta = dta %>% relocate(L, .after = Y)
dta = dta %>% relocate(K, .after = K)
# filtrando NAs
df.complete = dta[, c('Y', 'L', 'K')] %>% na.omit()
dta = merge(df.complete, dta, all.x = TRUE)


```

```{r}
#| tbl-cap: Modelo Gamma Log-linear
#| label: tbl-gama2

# Ajuste o modelo gama log-linear
fit_gamma <- glm(log(Y) ~ log(L) + log(K), family = Gamma(link = "log"), data = dta)

# Exiba os resultados
fit_gamma  %>% interpreta()   

```

O intercepto estimado de 1.61754583 (@tbl-gama2) representa o logaritmo
da produ√ß√£o quando tanto o trabalho (L) quanto o capital (K) s√£o iguais
a 1. Com um p-valor extremamente pequeno, o intercepto √©
estatisticamente significativo, indicando que ele desempenha um papel
importante na modelagem da vari√°vel dependente ùëåùëñ, ao n√≠vel de 5% de
signific√¢ncia.

O coeficiente para log(L) √© 0.02371, indicando que um aumento de 1% na
for√ßa de trabalho (L) leva a um aumento de aproximadamente 0.024% na
produ√ß√£o, mantendo o capital constante. O p-valor extremamente pequeno
indica que este coeficiente √© altamente significativo, o que valida a
import√¢ncia da for√ßa de trabalho na determina√ß√£o da produ√ß√£o no modelo.

O coeficiente para log(K) √© 0.06012, sugerindo que um aumento de 1% no
capital (K) resulta em um aumento de aproximadamente 0.060% na produ√ß√£o,
mantendo a for√ßa de trabalho constante. Com um p-valor extremamente
baixo, esse coeficiente √© altamente significativo, demonstrando que o
capital tem uma influ√™ncia importante e estatisticamente significativa
na produ√ß√£o.

O par√¢metro de dispers√£o estimado √© 0.00135, o que indica que h√° uma
baixa variabilidade dos dados em torno da m√©dia ajustada pelo modelo.
Isso sugere que o modelo gamma log-linear est√° capturando bem a
dispers√£o dos dados, com pouca heterogeneidade residual n√£o explicada
pelo modelo.

```{r}
# Estimativa dos coeficientes e vari√¢ncias
alpha_hat <- coef(fit_gamma )["log(L)"]
beta_hat <- coef(fit_gamma )["log(K)"]

# C√°lculo da soma dos coeficientes
soma_alpha_beta <- alpha_hat + beta_hat

# C√°lculo do erro padr√£o da soma dos coeficientes
vcov_matrix <- vcov(fit_gamma )
se_alpha_beta <- sqrt(vcov_matrix["log(L)", "log(L)"] + vcov_matrix["log(K)", "log(K)"] + 2 * vcov_matrix["log(L)", "log(K)"])

# C√°lculo da estat√≠stica t
t_statistic <- (soma_alpha_beta - 1) / se_alpha_beta

# C√°lculo do valor-p
p_value <- 2 * pt(-abs(t_statistic), df = df.residual(fit_gamma ))


```

```{r}
#| tbl-cap: Teste
#| label: tbl-teste

# Criando a tabela de resultados
resultados <- data.frame(
  Descri√ß√£o = c("Soma de alpha e beta", "Erro padr√£o", "Estat√≠stica t", "Valor-p", "Decis√£o"),
  Valor = c(
    round(soma_alpha_beta,4),
    round(se_alpha_beta,4),
    round(t_statistic,4),
    p_value,
    ifelse(p_value < 0.05, "Rejeitamos H0", "N√£o rejeitamos H0")
  )
)

# Exibir a tabela
kable(resultados)%>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necess√°rio


```

Decis√£o sobre Teste $ùêª0 : ùõº + ùõΩ = 1$ contra $ùêª1 : ùõº + ùõΩ ‚â† 1$:
(@tbl-teste) Como o valor-p √© extremamente pequeno, rejeitamos a
hip√≥tese nula $H_0$ indicando que a soma de $\alpha$ e $\beta$ √©
significativamente diferente de 1. Isso significa que a hip√≥tese de
retornos constantes √† escala n√£o √© v√°lida para os dados analisados.

Retornos constantes √† escala implicam que, se ambos os insumos (L e K)
aumentarem na mesma propor√ß√£o, a produ√ß√£o $Y_i$ tamb√©m aumentar√° na
mesma propor√ß√£o. No entanto, dado que a soma de $\alpha$ e $\beta$ √©
significativamente diferente de 1, isso sugere que os retornos √† escala
n√£o s√£o constantes para este modelo. Dependendo do valor espec√≠fico da
soma $(\alpha + \beta < 1$ ou $\alpha + \beta > 1)$, os retornos √†
escala podem ser decrescentes ou crescentes, respectivamente.

Assim, a soma de $\alpha$ e $\beta$ √© 0.08383678, o que est√° longe de 1,
indicando retornos decrescentes √† escala. Isso significa que aumentar
proporcionalmente a for√ßa de trabalho e o capital levar√° a um aumento
menos que proporcional na produ√ß√£o. Em outras palavras, conforme mais
insumos s√£o adicionados, a produtividade marginal desses insumos
diminui, levando a um crescimento menos eficiente da produ√ß√£o.

### An√°lise dos Res√≠duos

```{r}
#| tbl-cap: Gr√°fico de An√°lise de res√≠duos 
#| label: tbl-gamma1

library(lmtest)
ggresiduals(fit_gamma )

```

```{r}
fit_gammaa <-bptest(fit_gamma)

# Teste de Durbin-Watson
dw_test_gamma <- dwtest(fit_gamma)
```

```{r}
# Criando a tabela de resultados
test_results <- data.frame(
  Teste = c("Breusch-Pagan", "Durbin-Watson"),
  Estat√≠stica = c(2.6679, 2.1338),
  `Valor-p` = c(0.2634, 0.7801),
  Decis√£o = c(
    ifelse(0.2634 < 0.05, "Rejeitamos H0", "N√£o rejeitamos H0"),
    ifelse(0.7801 < 0.05, "Rejeitamos H0", "N√£o rejeitamos H0")
  )
)

# Exibir a tabela usando kable
kable(test_results, caption = "Resultados dos Testes de Breusch-Pagan e Durbin-Watson") %>%
  kable_styling(full_width = F, position = "center")%>%
    column_spec(2, width = "17em")  # Ajuste a largura conforme necess√°rio

```

Com base na an√°lise dos res√≠duos, incluindo os testes de Breusch-Pagan e
Durbin-Watson, podemos concluir o seguinte sobre o ajuste do modelo de
regress√£o:

**Homocedasticidade:** - A vari√¢ncia dos res√≠duos parece ser constante
em toda a faixa dos valores ajustados. Com o teste de Teste de
Breusch-Paga, com um valor-p de 0.2634, n√£o rejeitamos a hip√≥tese nula
de homocedasticidade. Isso significa que n√£o h√° evid√™ncias suficientes
para sugerir a presen√ßa de heterocedasticidade nos res√≠duos do modelo
gamma.

**Normalidade:** - Embora o teste de Shapiro-Wilk sugira que os res√≠duos
n√£o sigam uma distribui√ß√£o normal, desconsiderando caudas pesadas tanto
nos extremos inferiores quanto nos superiores, podemos aproximar que os
res√≠duos est√£o pr√≥ximos de uma distribui√ß√£o normal.

**Independ√™ncia dos Res√≠duos:** - Tanto o teste de Durbin-Watson quanto
a inspe√ß√£o do gr√°fico de res√≠duos versus valores ajustados na tabela
@tbl-gamma1 n√£o fornecem evid√™ncias significativas para rejeitar a
hip√≥tese nula de aus√™ncia de autocorrela√ß√£o positiva ou negativa nos
res√≠duos. Assim, parece que os res√≠duos s√£o independentes entre si, o
que √© uma boa indica√ß√£o de que o modelo est√° adequadamente ajustado
quanto a essa suposi√ß√£o.

**Linearidade:** - H√° um padr√£o claro nos res√≠duos plotados em rela√ß√£o
aos valores ajustados, indicando n√£o linearidade entre as vari√°veis
independentes e dependentes.

## Compara√ß√£o dos Modelos: Gamma Log-Linear vs. Modelo Normal

```{r,include=FALSE}
# Obter o log-likelihood dos modelos
logLik(fit_gamma)
logLik(fit)

```

```{r,include=FALSE}
# Obter o AIC dos modelos
AIC(fit_gamma)
AIC(fit)

```

```{r,include=FALSE}
# Obter o BIC dos modelos
BIC(fit_gamma)
BIC(fit)

```

```{r}
# Criar um data frame com os dados dos modelos
model_comparison <- data.frame(
  Crit√©rio = c("Log-Likelihood", "AIC", "BIC"),
  `Modelo Gamma Log-Linear` = c(-83.07791, 174.1558, 186.0351),
  `Modelo Normal` = c(-59.39108, 126.7822, 138.6614)
)

# Exibir a tabela usando kable
kable(model_comparison, caption = "Compara√ß√£o dos Modelos Gamma Log-Linear e Normal")%>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necess√°rio

```

Log-Likelihood (Log-Verossimilhan√ßa) - **Modelo Gamma Log-Linear**:
-83.07791 - **Modelo Normal**: -59.39108

O valor de log-likelihood mais alto (menos negativo) indica um melhor
ajuste do modelo aos dados. O modelo normal tem um valor de
log-likelihood mais alto, sugerindo que se ajusta melhor aos dados em
compara√ß√£o com o modelo Gamma log-linear.

Crit√©rio de Informa√ß√£o de Akaike (AIC) - **Modelo Gamma Log-Linear**:
174.1558 - **Modelo Normal**: 126.7822

Valores menores de AIC indicam um modelo mais eficiente em termos de
ajuste aos dados com penaliza√ß√£o pela complexidade. O modelo normal
apresenta um AIC significativamente menor, indicando que √© mais
eficiente e se ajusta melhor aos dados do que o modelo Gamma log-linear.

Crit√©rio de Informa√ß√£o de Bayes (BIC) - **Modelo Gamma Log-Linear**:
186.0351 - **Modelo Normal**: 138.6614

O BIC tamb√©m penaliza a complexidade do modelo e valores menores indicam
um ajuste melhor com menor penaliza√ß√£o por complexidade. Novamente, o
modelo normal apresenta um BIC significativamente menor, refor√ßando que
√© mais adequado para os dados em compara√ß√£o ao modelo Gamma log-linear.

Com base nos crit√©rios de log-likelihood, AIC e BIC, o **modelo normal**
√© a melhor escolha. Ele n√£o s√≥ se ajusta melhor aos dados (conforme
indicado pelo log-likelihood), mas tamb√©m √© mais eficiente e simples em
termos de complexidade (conforme indicado pelos valores de AIC e BIC).

Portanto, o modelo normal √© prefer√≠vel ao modelo Gamma log-linear para a
an√°lise dos seus dados, oferecendo um melhor equil√≠brio entre ajuste e
complexidade.

# Dados Kaggle - an√°lise de clssifica√ß√£o de cr√©dito

## Modelo Logistico

Para este estudo, utilizamos uma base de dados obtida do Kaggle, que
cont√©m informa√ß√µes detalhadas sobre clientes de uma institui√ß√£o
financeira. O objetivo principal √© desenvolver um modelo de machine
learning para classificar o cr√©dito dos clientes em diferentes faixas de
risco, otimizando os processos de decis√£o e reduzindo esfor√ßos manuais.
A base de dados inclui 100.000 observa√ß√µes e 28 vari√°veis, como idade,
ocupa√ß√£o, renda anual, n√∫mero de contas banc√°rias e hist√≥rico de
pagamentos.

A an√°lise foca na constru√ß√£o e avalia√ß√£o de um modelo de **regress√£o
log√≠stica**, adequado para situa√ß√µes em que a vari√°vel dependente √©
categ√≥rica, como a classifica√ß√£o de cr√©dito ("Poor" e "Good"). A
**regress√£o log√≠stica** estima a probabilidade de um evento bin√°rio
ocorrer e classifica as observa√ß√µes em categorias. A equa√ß√£o do modelo
log√≠stico √© expressa como:

$$log(p / (1 - p)) = Œ≤0 + Œ≤1 * X_1 + Œ≤2 * X_2 + ... + Œ≤p * X_p$$

Onde:

-   $p$ √© a probabilidade de um cliente ser classificado como "Good"
    (cliente ser um bom pagador).

-   $1-p$ √© a probabilidade de um cliente ser classificado como "Poor"
    (cliente possui um hist√≥rico problem√°tico).

-   $X_1, X_2, ..., X_p$ s√£o as vari√°veis independentes (como hist√≥rico
    de pagamentos, d√≠vida pendente, etc.)

-   $\beta_0, \beta_1, ..., \beta_p$ s√£o os coeficientes que medem o
    impacto de cada vari√°vel independente na probabilidade de ser
    classificado como "Good".

Como parte da an√°lise, ser√° explorado o ajuste do modelo, avaliando os
res√≠duos para verificar a adequa√ß√£o do modelo.

```{r}
## carregando dados: base teste (Kaggle)
## - os dados s√£o carregados no objeto "dta"
setwd("C:/Users/eliana.cardoso/OneDrive - Funda√ß√£o Dom Cabral/Documentos/GitHub/Trabalhodemlg")

dta_teste = read.csv('_dta/test.csv') #credit_scoring
dta_treino = read.csv('_dta/train.csv')

# dim(dta_treino)

```

```{r}
# Limpeza da base
# Selecionando vari√°veis necess√°rias
dta <- subset(dta_treino, select = c(Credit_Score,Credit_Mix, Outstanding_Debt, Payment_of_Min_Amount, Changed_Credit_Limit))

# Checando valores ausentes
valores_faltantes <-data.frame(sort(colSums(is.na(dta)), decreasing = TRUE))

# Preparando a vari√°vel dependente
dta = dta %>% dplyr::filter(Credit_Score != "Standard")

dta$Credit_Score <- factor(dta$Credit_Score, levels = c('Good', 'Poor'))

# Preparando preditores cont√≠nuos
dta$Outstanding_Debt <- as.numeric(str_extract(dta$Outstanding_Debt, "[0-9.]+"))
dta <- dta[which(dta$Changed_Credit_Limit != "_"), ]
dta$Changed_Credit_Limit <- as.numeric(dta$Changed_Credit_Limit)

# Preparando preditores categ√≥ricos
dta <- dta[which(dta$Credit_Mix != "_"), ]
dta$Credit_Mix <- factor(dta$Credit_Mix, levels = c('Good', 'Standard', 'Bad'))
dta <- dta[which(dta$Payment_of_Min_Amount != "NM"), ]
dta$Payment_of_Min_Amount <- factor(dta$Payment_of_Min_Amount, levels = c('No', 'Yes'))

# An√°lise descritiva
summary_dta3<-summary(dta)



```

```{r}

summary_table <- data.frame(
  Vari√°vel = c("Credit_Score", "Credit_Mix", "Outstanding_Debt", "Payment_of_Min_Amount", "Changed_Credit_Limit"),
  Estat√≠stica = c(
    "Good: 12192, Poor: 19884", 
    "Good: 13518, Standard: 8509, Bad: 10049", 
    "Min.: 0.23, 1st Qu.: 702.54, Median: 1360.45, Mean: 1593.26, 3rd Qu.: 2258.30, Max.: 4998.07",
    "No: 14432, Yes: 17644", 
    "Min.: -6.480, 1st Qu.: 4.570, Median: 8.560, Mean: 9.573, 3rd Qu.: 13.130, Max.: 35.820"
  )
)

# Exibir a tabela usando kable
kable(summary_table, caption = "Resumo Descritivo das Vari√°veis") %>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necess√°rio

```

A an√°lise descritiva das vari√°veis na base de dados dta revela que, dos
32.076 clientes analisados, 12.192 foram classificados como "Good" e
19.884 como "Poor", indicando que a maioria dos clientes tem uma
classifica√ß√£o de cr√©dito ruim. A vari√°vel Credit_Mix mostra que a
maioria dos clientes tem uma mistura de cr√©dito considerada "Good",
seguida por "Standard" e "Bad", o que pode influenciar a classifica√ß√£o
final de risco. Em rela√ß√£o √† d√≠vida pendente, os valores variam
significativamente, com uma mediana de 1.360,45 e uma m√©dia de 1.593,26,
sugerindo que alguns clientes t√™m d√≠vidas elevadas, o que pode aumentar
o risco de cr√©dito. Quanto ao pagamento do valor m√≠nimo, 17.644 clientes
o fizeram, enquanto 14.432 n√£o, indicando que pagar apenas o valor
m√≠nimo pode ser um indicador de problemas financeiros. A vari√°vel
Changed_Credit_Limit mostra varia√ß√µes entre -6,48 e 35,82, com uma
mediana de 8,56, sugerindo mudan√ßas no comportamento de cr√©dito ao longo
do tempo. Essas observa√ß√µes iniciais s√£o fundamentais para a constru√ß√£o
do modelo de regress√£o log√≠stica e devem orientar a escolha de vari√°veis
e a interpreta√ß√£o dos resultados.

```{r}
# An√°lise associativa preliminar
# Boxplot para Outstanding_Debt por Credit_Score
boxplot(Outstanding_Debt ~ Credit_Score, data = dta,
        main = "Distribui√ß√£o da D√≠vida Pendente por Classifica√ß√£o de Cr√©dito")
# Boxplot para Changed_Credit_Limit por Credit_Score
boxplot(Changed_Credit_Limit ~ Credit_Score, data = dta,
        main = "Varia√ß√£o no Limite de Cr√©dito por Classifica√ß√£o de Cr√©dito")
```

```{r}

# Executa os testes qui-quadrado
test1 <- chisq.test(x = dta$Credit_Mix, y = dta$Credit_Score)
test2 <- chisq.test(x = dta$Payment_of_Min_Amount, y = dta$Credit_Score)

chi_square_results <- data.frame(
  Teste = c("Credit_Mix vs Credit_Score", "Payment_of_Min_Amount vs Credit_Score"),
  Estat√≠stica = c(14606, 14578),
  `Graus de Liberdade` = c(2, 1),
  `Valor-p` = c("< 2.2e-16", "< 2.2e-16"),
  Decis√£o = c(
    "Rejeitamos H0",
    "Rejeitamos H0"
  )
)

# Exibir a tabela usando kable
kable(chi_square_results, caption = "Resultados dos Testes Qui-Quadrado") %>%
  kable_styling(full_width = F, position = "center")

```

A an√°lise associativa preliminar entre as vari√°veis do estudo revela
insights importantes sobre os padr√µes de cr√©dito dos clientes. Atrav√©s
dos boxplots, observa-se que a d√≠vida pendente (Outstanding_Debt) tende
a ser maior entre os clientes com uma classifica√ß√£o de cr√©dito "Poor" em
compara√ß√£o com aqueles classificados como "Good". Isso sugere que
clientes com maiores d√≠vidas s√£o mais propensos a terem uma
classifica√ß√£o de cr√©dito inferior. Al√©m disso, as mudan√ßas no limite de
cr√©dito (Changed_Credit_Limit) tamb√©m variam significativamente entre as
classifica√ß√µes de cr√©dito, com clientes de cr√©dito "Poor" exibindo maior
varia√ß√£o, o que pode indicar instabilidade financeira.

As an√°lises de qui-quadrado entre as vari√°veis categ√≥ricas refor√ßam
essas observa√ß√µes. O teste de associa√ß√£o entre a mistura de cr√©dito
(Credit_Mix) e a classifica√ß√£o de cr√©dito (Credit_Score) resultou em um
valor de X¬≤ de 14.606 com um p-valor extremamente significativo (\<
2,2e-16), indicando uma forte associa√ß√£o entre essas vari√°veis. Isso
sugere que a composi√ß√£o do cr√©dito do cliente tem uma influ√™ncia
consider√°vel sobre sua classifica√ß√£o de cr√©dito. De forma similar, o
teste de qui-quadrado entre o pagamento do valor m√≠nimo
(Payment_of_Min_Amount) e a classifica√ß√£o de cr√©dito tamb√©m mostrou uma
associa√ß√£o significativa (X¬≤ = 14.578, p \< 2,2e-16), sugerindo que
clientes que n√£o pagam o valor m√≠nimo regularmente t√™m maior
probabilidade de serem classificados como "Poor". Esses resultados
preliminares fornecem evid√™ncias robustas de que vari√°veis financeiras e
comportamentais desempenham um papel crucial na determina√ß√£o do risco de
cr√©dito, justificando sua inclus√£o no modelo de regress√£o log√≠stica
subsequente.

### Modelo log√≠stico ajustado

O modelo de regress√£o log√≠stica ajustado para classificar o cr√©dito dos
clientes foi desenvolvido utilizando A fun√ß√£o de link utilizada foi a
logit, adequada para a an√°lise de vari√°veis bin√°rias como o
Credit_Score.

Al√©m disso, para a constru√ß√£o do modelo foram utilizadas as seguintes
vari√°veis:

```{r}
# Ajuste do modelo de regress√£o log√≠stica
out <- glm(Credit_Score ~ Credit_Mix + Outstanding_Debt + Payment_of_Min_Amount + Changed_Credit_Limit, 
           family = binomial(link = logit), data = dta)

tabela<-as.data.frame(coef(summary(out)))
tabela <- cbind(Covariavel = rownames(tabela), tabela)

# Cria√ß√£o da tabela com os resultados
tabela_formatada <- data.frame(
  Vari√°vel = tabela$Covariavel,
  Estimacao = tabela$Estimate,
  ErroPadrao = tabela$`Std. Error`,
  Pvalor = ifelse(tabela$`Pr(>|z|)` < 0.05, "< 0.05", format(tabela$`Pr(>|z|)`, digits = 4, nsmall = 4))
)

# Exibindo a tabela
kable(tabela_formatada, caption = "Resultados do Modelo de Regress√£o Log√≠stica") %>%
  kable_styling(full_width = F, position = "center")


```

Os coeficientes do modelo s√£o significativos, com valores de p
inferiores a 0,05 para todas as vari√°veis, indicando que elas t√™m uma
contribui√ß√£o estatisticamente significativa na previs√£o da classifica√ß√£o
de cr√©dito.

Aqui, o intercepto √© ‚àí1.485, enquanto os coeficientes para as vari√°veis
Credit_MixStandard e Credit_MixBad s√£o positivos e relativamente altos,
o que sugere um efeito significativo na probabilidade de um cliente ser
classificado como "Good". Outstanding_Debt e Payment_of_Min_AmountYes
tamb√©m apresentam coeficientes positivos, refletindo seu impacto
positivo na probabilidade de uma boa classifica√ß√£o de cr√©dito. O
coeficiente de Changed_Credit_Limit √© negativo, indicando que um aumento
no limite de cr√©dito alterado est√° associado a uma menor probabilidade
de classifica√ß√£o positiva.

O modelo apresenta um desvio nulo de 42604 e um desvio residual de
24833. A redu√ß√£o no desvio residual em rela√ß√£o ao desvio nulo indica que
o modelo com as vari√°veis independentes tem um ajuste significativamente
melhor do que o modelo nulo. Em outras palavras, o modelo ajustado reduz
a discrep√¢ncia entre os valores previstos e os observados de forma
significativa.

Quanto ao AIC, vale salientar que O AIC √© uma m√©trica que ajuda a
avaliar a qualidade do ajuste do modelo, levando em considera√ß√£o tanto a
complexidade quanto a adequa√ß√£o ao conjunto de dados. A principal fun√ß√£o
do AIC √© penalizar modelos mais complexos, que possuem um maior n√∫mero
de par√¢metros, para evitar o ajuste excessivo aos dados (overfitting).No
caso, o AIC obtido foi de 24845. Para determinar se este valor indica um
bom ajuste do modelo, √© necess√°rio compar√°-lo com o AIC de outros
modelos que voc√™ pode ter testado.

Para o modelo ajustado foi calculado tamb√©m a raz√£o de chances:

```{r}
# Calcular raz√µes de chances (odds ratios)
OR <- exp(coef(out))

or_table <- data.frame(
  Odds_Ratio = round(OR, 3)
)

# Imprimir a tabela com kable
kable(or_table, caption = "Raz√µes de Chances (Odds Ratios) do Modelo de Regress√£o Log√≠stica")

```

As raz√µes de chances (odds ratios) para o modelo de regress√£o log√≠stica
ajustado fornecem uma vis√£o sobre como cada vari√°vel preditora afeta a
probabilidade de uma boa classifica√ß√£o de cr√©dito. As vari√°veis
"Credit_MixStandard" e "Credit_MixBad" t√™m odds ratios de
aproximadamente 2.75 e 10.43, respectivamente, indicando que os
indiv√≠duos com essas classifica√ß√µes de cr√©dito t√™m odds
significativamente maiores de obter uma boa classifica√ß√£o em compara√ß√£o
com a categoria de refer√™ncia. O valor da d√≠vida pendente
("Outstanding_Debt") tem um odds ratio pr√≥ximo de 1, sugerindo que sua
influ√™ncia nas odds √© m√≠nima. Por outro lado, pagar o valor m√≠nimo
requerido ("Payment_of_Min_AmountYes") aumenta as odds de uma boa
classifica√ß√£o de cr√©dito em cerca de 4.15 vezes. O limite de cr√©dito
alterado ("Changed_Credit_Limit") tem um odds ratio de 0.98, indicando
uma leve diminui√ß√£o nas odds de uma boa classifica√ß√£o com cada unidade
adicional de altera√ß√£o no limite de cr√©dito. Esses resultados ajudam a
entender a import√¢ncia relativa de cada vari√°vel na previs√£o da
classifica√ß√£o de cr√©dito.

Tentamos ajustar o modelo logistico, re-escalando Outstanding Debt:

```{r}
dta$Outstanding_Debt_scaled = dta$Outstanding_Debt/100

# estima√ß√£o
out_reescalado = glm(Credit_Score ~ 
            Credit_Mix + Outstanding_Debt_scaled +
            Payment_of_Min_Amount + Changed_Credit_Limit, 
            family = binomial(link = logit),
            data = dta)



tabela<-as.data.frame(coef(summary(out_reescalado)))
tabela <- cbind(Covariavel = rownames(tabela), tabela)

# Cria√ß√£o da tabela com os resultados
tabela_formatada <- data.frame(
  Vari√°vel = tabela$Covariavel,
  Estimacao = tabela$Estimate,
  ErroPadrao = tabela$`Std. Error`,
 Pvalor = ifelse(tabela$`Pr(>|z|)` < 0.05, "< 0.05", format(tabela$`Pr(>|z|)`, digits = 4, nsmall = 4)))

tabela_formatada$Pvalor <- format(tabela_formatada$Pvalor, scientific = TRUE, digits = 5)

# Exibindo a tabela
kable(tabela_formatada, caption = "Resultados do Modelo de Regress√£o Log√≠stica") %>%
  kable_styling(full_width = F, position = "center")




```

Visando verificar se √© poss√≠vel melhorar o modelo log√≠stico ajustado, a
vari√°vel Outstanding_Debt foi recalibrada. No modelo anterior, o
coeficiente para Outstanding_Debt era muito pequeno (6.567e-04),
enquanto no modelo ajustado com a vari√°vel escalada
(Outstanding_Debt_scaled), a estimativa do coeficiente foi
significativamente maior (0.065672), indicando um efeito mais expressivo
da vari√°vel escalada. No entanto, apesar de a escalagem ter melhorado a
interpreta√ß√£o dos coeficientes, os desvios nulo e residual, assim como o
AIC, permaneceram inalterados (o AIC √© 24845 para ambos os modelos).
Isso sugere que, embora a escalagem tenha proporcionado coeficientes
mais interpret√°veis, ela n√£o resultou em uma melhoria no ajuste global
do modelo.

### An√°lise dos Res√≠duos

A an√°lise dos res√≠duos √© crucial para avaliar se o modelo log√≠stico est√°
bem ajustado. Res√≠duos bem comportados, ou seja, sem padr√µes claros e
distribu√≠dos de forma aleat√≥ria, indicam que o modelo √© adequado. Se
houver padr√µes nos res√≠duos, isso pode sugerir que o modelo n√£o est√°
capturando toda a variabilidade dos dados, podendo haver vari√°veis
importantes faltantes ou problemas de especifica√ß√£o do modelo

```{r}

ggresiduals(out)

```

```{r,include=FALSE}

bptest(out)

# Teste de Durbin-Watson
dw_test2 <- dwtest(out)

```

```{r}
# Carregar pacotes necess√°rios
library(knitr)
library(kableExtra)

# Resultados dos testes
bp_test <- c("BP = 3931.9", "df = 5", "p-value < 2.2e-16")
dw_test <- c("DW = 0.65232", "p-value < 2.2e-16")

# Criar data frame para os resultados
test_results <- data.frame(
  Teste = c("Breusch-Pagan", "Durbin-Watson"),
  Estatistica = c("BP = 3931.9", "DW = 0.65232"),
  Graus_de_Liberdade = c("df = 5", NA),
  P_valor = c("p-value < 2.2e-16", "p-value < 2.2e-16")
)

# Exibir a tabela usando kable
kable(test_results, caption = "Resultados dos Testes Breusch-Pagan e Durbin-Watson") %>%
  kable_styling(full_width = F, position = "center")

```

Com base nos resultados obtidos via Teste de Breusch-Pagan e Teste de
Durbin-Watson, podemos concluir o seguinte sobre o ajuste do modelo de
regress√£o log√≠stica:

**Homocedasticidade:** - O Teste de Breusch-Pagan resultou em um valor
de BP = 3931.9 com um valor-p \< 2.2e-16. Esse valor-p extremamente
baixo indica que rejeitamos a hip√≥tese nula de homocedasticidade. Em
outras palavras, h√° evid√™ncias significativas de heterocedasticidade nos
res√≠duos do modelo. Isso sugere que a vari√¢ncia dos res√≠duos n√£o √©
constante ao longo dos valores preditores, o que pode indicar que o
modelo n√£o est√° capturando completamente a variabilidade dos dados.

**Independ√™ncia dos Res√≠duos:** - O Teste de Durbin-Watson forneceu um
valor de DW = 0.65232 com um valor-p \< 2.2e-16, indicando uma forte
presen√ßa de autocorrela√ß√£o positiva nos res√≠duos. Isso sugere que os
res√≠duos n√£o s√£o independentes entre si, o que pode indicar que o modelo
n√£o est√° capturando todos os padr√µes nos dados ou que h√° uma estrutura
de depend√™ncia n√£o modelada.

A inspe√ß√£o do gr√°fico de res√≠duos versus valores ajustados tamb√©m pode
revelar padr√µes adicionais que confirmem a presen√ßa de autocorrela√ß√£o.

**Linearidade:** - H√° um padr√£o claro nos res√≠duos plotados em rela√ß√£o
aos valores ajustados, indicando n√£o linearidade entre as vari√°veis
independentes e dependentes.

Desse modo, os resultados sugerem que o modelo enfrenta problemas de
heterocedasticidade e autocorrela√ß√£o positiva dos res√≠duos, o que pode
impactar a precis√£o e a validade do modelo.

### An√°lise do VIF (Variance Inflation Factor)

O VIF (Fator de Infla√ß√£o da Vari√¢ncia) √© uma medida importante para
identificar a presen√ßa de multicolinearidade entre os preditores em um
modelo de regress√£o. Valores elevados de VIF sugerem que um preditor
est√° altamente correlacionado com outros preditores no modelo, o que
pode inflacionar os erros padr√£o das estimativas dos coeficientes e
dificultar a identifica√ß√£o da real signific√¢ncia das vari√°veis.

```{r}
# Resultados do VIF
vif_results <- data.frame(
  Preditor = c("Credit_Mix", "Outstanding_Debt", "Payment_of_Min_Amount", "Changed_Credit_Limit"),
  GVIF = c(5.405144, 1.626080, 5.496045, 1.558789),
  Df = c(2, 1, 1, 1),
  'Ajuste do GVIF' = c(1.524761, 1.275178, 2.344365, 1.248515)
)

# Exibir a tabela usando kable
kable(vif_results, caption = "VIF dos Preditores") %>%
  kable_styling(full_width = F, position = "center")

```

```{r}
# Resultados dos erros padr√£o dos coeficientes
errors_std_results <- data.frame(
  Coeficiente = c("Intercept", "Credit_MixStandard", "Credit_MixBad", 
                  "Outstanding_Debt", "Payment_of_Min_AmountYes", 
                  "Changed_Credit_Limit"),
  Erro_Padr√£o = c(0.0361200, 0.0701266, 0.1036433, 
                  0.0000294, 0.0804651, 0.0036734)
)

# Exibir a tabela usando kable
kable(errors_std_results, caption = "Erros Padr√£o dos Coeficientes") %>%
  kable_styling(full_width = F, position = "center")
```

No modelo analisado, observamos que as vari√°veis Credit_Mix e
Payment_of_Min_Amount t√™m VIFs relativamente altos, com valores de 5.41
e 5.50, respectivamente. Esses valores indicam uma alta colinearidade
com outras vari√°veis do modelo. Isso √© corroborado pelos erros padr√£o
dos coeficientes: Credit_MixStandard e Credit_MixBad apresentam erros
padr√£o elevados, especialmente Credit_MixBad com um erro padr√£o de
0.1036, o que sugere que as estimativas dos coeficientes para estas
vari√°veis s√£o menos precisas e podem ser afetadas pela
multicolinearidade.

Em contraste, Outstanding_Debt e Changed_Credit_Limit t√™m VIFs baixos,
de 1.63 e 1.56, respectivamente. Isso sugere que estas vari√°veis t√™m
baixa colinearidade com outras vari√°veis do modelo. O erro padr√£o para
Outstanding_Debt √© extremamente pequeno (aproximadamente 0.0000),
indicando uma estimativa muito precisa para o coeficiente desta
vari√°vel. Da mesma forma, Changed_Credit_Limit tem um erro padr√£o muito
pequeno (0.0037), o que tamb√©m sugere uma estimativa precisa para o
coeficiente desta vari√°vel.

Por outro lado, o erro padr√£o para Payment_of_Min_AmountYes √©
relativamente grande (0.0805), o que pode refletir a alta
multicolinearidade observada pelo VIF elevado para
Payment_of_Min_Amount. Isso indica que a estimativa do coeficiente para
esta vari√°vel pode ser menos confi√°vel.

Em resumo, a alta multicolinearidade identificada para Credit_Mix e
Payment_of_Min_Amount est√° associada a erros padr√£o mais altos para
essas vari√°veis, o que sugere que as estimativas dos coeficientes podem
ser imprecisas. Em contraste, vari√°veis com VIFs baixos como
Outstanding_Debt e Changed_Credit_Limit apresentam erros padr√£o menores
e estimativas mais confi√°veis. Considerar a remo√ß√£o ou ajuste das
vari√°veis com alta colinearidade pode melhorar a precis√£o e robustez do
modelo.
