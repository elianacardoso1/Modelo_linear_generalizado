---
title: "Trabalho MLG"
subtitle: ""
author: "Eliana Cardoso Gon√ßalves e Sophia Araujo de Moraes"
date: "08/26/2024"
date-format: short # formata√ß√£o dd/mm/aaaa
lang: pt # linguagem
toc: true # √≠ndice
number-sections: true
fig-cap-location: top # localiza√ß√£o t√≠tulo figura 
geometry:
  - top=3cm
  - left=3cm
  - right=2cm
  - bottom=2cm
tbl-cap-location: top
df-print: kable # sa√≠da dos data frames serem kable
fig-width: 10
fig-height: 4
format: 
  html:
    self-contained: true # tornar o html compartilh√°vel
    theme: flatly
  pdf: 
    documentclass: scrreprt
  docx: default
editor:
  markdown:
    wrap: 72
editor_options:
  chunk_output_type: console
output: 
  pdf_document:
    margin: 1in
    df_print:
      digits: 3
  word_document:
    fig_caption: true
    df_print: kable
prefer-html: true
execute:
  echo: false
  warning: false
---

```{r}
rm(list = ls())

if(!require(remotes)) install.packages("remotes")
remotes::install_github("fndemarqui/reglin")
```

```{r,biblioteca}


if (!require(pacman))(install.packages("pacman"))(require(pacman))
pacman::p_load( kableExtra, corrplot, haven, ggplot2, 
  tidyverse, performance, see, car, 
  knitr, patchwork, summarytools, 
  caret, pROC, dplyr, reglin, dplyr)

```

```{r,diretorio}

source("_src/src.R")

```

# An√°lise Descritiva

```{r}
dta = read_dta("_dta/pwt1001.dta")
# filtrando para 2014
dta = dta %>% subset(year == '2014')
```

```{r}
## criando as vari√°veis de interesse
# definindo as vari√°veis
dta$Y = dta$rgdpo
dta$L = dta$emp*dta$hc
dta$K = dta$rnna
# rearranjando colunas
dta = dta %>% relocate(Y, .after = year)
dta = dta %>% relocate(L, .after = Y)
dta = dta %>% relocate(K, .after = K)
# filtrando NAs
df.complete = dta[, c('Y', 'L', 'K')] %>% na.omit()
dta = merge(df.complete, dta, all.x = TRUE)


```

```{r}
#| label: tbl-t1
#| tbl-cap: Tabela Resumo das Vari√°veis Y, L e K.


descr_stats <- descr(dta[, c('Y', 'L', 'K')], 
                     stats = c("mean", "sd", "min", "med", "max"), 
                     transpose = FALSE, 
                     headings = FALSE)

# Convertendo para um dataframe para facilitar a manipula√ß√£o
descr_df <- as.data.frame(descr_stats)

# Adicionando a coluna de Estat√≠sticas
descr_df <- descr_df %>%
  select( everything())

# Exibindo a tabela formatada em markdown
library(knitr)
kable(descr_df, format = "markdown")

```

```{r}
#| label: fig-y
#| fig-cap: Histograma PIB Nacional (Y) em d√≥lares PPP de 2014


hist_data = hist(dta$Y, xlab = 'Y', main = '', col = 'lightblue')
# dist. normal (p/ compara√ß√£o)
x_values = seq(min(dta$Y), max(dta$Y), length = 100)
y_values = dnorm(x_values, mean = mean(dta$Y), sd = sd(dta$Y)) 
y_values = y_values * diff(hist_data$mids[1:2]) * length(dta$Y) 
lines(x_values, y_values, lwd = 2)



```

Observando o @fig-y e @tbl-t1 , o valor m√≠nimo do PIB √© \$2.569,
enquanto o valor m√°ximo √© significativamente maior, chegando a
\$18.244.220, indicando uma grande varia√ß√£o no PIB entre os pa√≠ses da
amostra.A m√©dia do PIB √© \$769.941, o que √© substancialmente maior que a
mediana de \$123.419, sugerindo que alguns pa√≠ses com PIB muito alto
est√£o puxando a m√©dia para cima. A distribui√ß√£o do PIB √© bastante
assim√©trica, com muitos pa√≠ses tendo PIBs relativamente baixos e poucos
pa√≠ses com PIBs muito altos.

```{r}
#| label: fig-l
#| fig-cap: Histograma For√ßa de Trabalho (L)


p = ggplot(dta, aes(x = L)) +
  # histograma
  geom_histogram(aes(x = L, after_stat(density)), fill = 'lightblue', col = 'black', bins = 10) +
  # dist. normal (p/ compara√ß√£o)
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$L), sd = sd(dta$L))) + 
  # label eixo x
  xlab('L') +
  # label eixo y
  ylab('Density') +
  # tema do plot
  theme(
    # painel
    panel.background = element_blank(),
    panel.border = element_blank(),
    # eixos
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )
p

```

Analisando o @fig-l e a @tbl-t1, a varia√ß√£o da for√ßa de trabalho de
0,2994 a 2.045,91 reflete uma grande disparidade na popula√ß√£o
economicamente ativa entre os pa√≠ses. Com uma m√©dia de 54,60 e uma
mediana de 11,65, a distribui√ß√£o mostra-se assim√©trica, sugerindo a
presen√ßa de pa√≠ses com for√ßas de trabalho extremas, seja pela sua
grandeza ou pequenez em rela√ß√£o √† m√©dia da amostrm alguns pa√≠ses com
pa√≠ses com a for√ßa de trabalho outlier.

```{r}
#| fig-cap: Histograma Estoque de Capital (K) em d√≥lares PPP de 2014)
#| label: fig-k

## histograma K
# invocando ggplot
p = ggplot(dta, aes(x = K)) +
  # histograma
  geom_histogram(aes(x = K, after_stat(density)), fill = 'lightblue', col = 'black', bins = 10) +
  # dist. normal (p/ compara√ß√£o)
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$K), sd = sd(dta$K))) + 
  # label eixo x
  xlab('K') +
  # label eixo y
  ylab('Density') +
  # tema do plot
  theme(
    # painel
    panel.background = element_blank(),
    panel.border = element_blank(),
    # eixos
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )
p

```

Analisando os valores da @tbl-t1 e @fig-k ,
observamos que o estoque de capital varia amplamente, de \$7.345 a
\$64.118.472, indicando diferen√ßas significativas no n√≠vel de
investimento em capital produtivo entre os pa√≠ses.

A m√©dia do estoque de capital √© \$3.058.761, consideravelmente maior que
a mediana de \$394.841, o que sugere que alguns pa√≠ses t√™m estoques de
capital extremamente altos que est√£o elevando a m√©dia.

# Modelo Log-Normal

Este estudo se concentra em uma amostra de 144 pa√≠ses distintos no ano
de 2014, utilizando um modelo linear normal para explorar como a for√ßa
de trabalho e o estoque de capital influenciam o PIB. A regress√£o linear
m√∫ltipla ser√° empregada para estimar os coeficientes que quantificam
essas rela√ß√µes, permitindo-nos compreender melhor os determinantes do
crescimento econ√¥mico.

Essa rela√ß√£o pode ser expressa pela seguinte equa√ß√£o:

$$Y=Œ≤0+Œ≤1X1+Œ≤2X2+...+Œ≤pXp+Œµ$$

Onde:

$Y$ √© a vari√°vel dependente ( PIB Nacional (Y) em d√≥lares PPP de 2014).

$X1,X2,...,Xp$ s√£o as vari√°veis independentes ( For√ßa de Trabalho (L)e o
Estoque de Capital (K) em d√≥lares PPP de 2014).

$Œ≤1,Œ≤2,...,Œ≤p$ s√£o os coeficientes de regress√£o que representam os
efeitos das vari√°veis independentes na vari√°vel dependente.

$Œµ$ √© o termo de erro, que representa a varia√ß√£o n√£o explicada pelo
modelo.

Para garantir a robustez e confiabilidade dos resultados, optamos por
realizar uma transforma√ß√£o log-log nas vari√°veis, considerando que o PIB
Nacional (Y) em d√≥lares PPP de 2014, juntamente com as vari√°veis
independentes "for√ßa de trabalho" e "estoque de capital", n√£o apresentam
uma distribui√ß√£o normal. Essa abordagem vai permitir que aos
pressupostos do modelo normal sejam atendidos e obter resultados mais
consistentes.

Ao aplicar a transforma√ß√£o log-log, estamos ajustando a distribui√ß√£o das
vari√°veis para se adequarem melhor ao modelo, mitigando quaisquer
distor√ß√µes ou vi√©s que possam surgir devido √† falta de normalidade. Isso
nos permite realizar infer√™ncias estat√≠sticas mais confi√°veis e
interpretar os efeitos das vari√°veis independentes sobre o PIB Nacional
de forma mais precisa.

Essa estrat√©gia de transforma√ß√£o aumenta a robustez da an√°lise, pois
reduz a influ√™ncia de valores extremos e torna os resultados menos
sens√≠veis a distribui√ß√µes n√£o normais. Portanto, podemos ter maior
confian√ßa nas conclus√µes derivadas do modelo, garantindo uma abordagem
metodol√≥gica s√≥lida e resultados mais confi√°veis para tomada de decis√£o.

## Resultados

A an√°lise macroecon√¥mica √© fundamental para entender o desenvolvimento
econ√¥mico e social dos pa√≠ses. No contexto da contabilidade nacional,
vari√°veis como o Produto Interno Bruto (PIB), a for√ßa de trabalho e o
estoque de capital s√£o essenciais para avaliar a produtividade e o
crescimento econ√¥mico. Este estudo utiliza dados da Penn World Table de
2020 para investigar a rela√ß√£o entre essas vari√°veis.

O PIB nacional (Y), medido em d√≥lares PPC de 2014, √© uma medida
abrangente da atividade econ√¥mica de um pa√≠s. A for√ßa de trabalho (L)
representa o total de pessoas empregadas ou em busca de emprego,
refletindo a capacidade produtiva humana. O estoque de capital (K),
tamb√©m medido em d√≥lares PPC de 2014, indica o valor total dos ativos
produtivos de um pa√≠s, como m√°quinas, edif√≠cios e infraestrutura.

Ao analisar essas vari√°veis, o objetivo √© fornecer insights sobre as
pol√≠ticas econ√¥micas que podem fomentar o crescimento e a produtividade.
Esta investiga√ß√£o pode ajudar formuladores de pol√≠ticas, economistas e
pesquisadores a identificar √°reas-chave para interven√ß√£o e investimento,
promovendo um desenvolvimento econ√¥mico sustent√°vel e inclusivo.

```{r}
#| label: tbl-t2
#| tbl-cap: Ajuste do Modelo de Regress√£o Log-Normal 

fit = lm(log(Y) ~ log(L) + log(K), data = dta)
# resultados
interpreta <- function(mod, alpha = 0.05) {
  tab <- summary(mod)
  tabela <- as.data.frame(coef(tab))
  tabela <- cbind(Covariavel = rownames(tabela), tabela)
  tabela <- tabela %>%
    mutate(
      Estima√ß√£o = Estimate,
      Pvalor = `Pr(>|t|)`,
      sig = case_when(
        is.na(`Pr(>|t|)`) ~ " ",
        `Pr(>|t|)` < 0.001 ~ "<0.001***",
         `Pr(>|t|)` <= alpha ~ paste0(" ", format(`Pr(>|t|)`, digits = 3), "*"),
        TRUE ~ paste0(" ", format(`Pr(>|t|)`, digits = 3))
      )
    ) %>%
    select( Estima√ß√£o, Pvalor, sig)
  
  return(tabela)
}



  

fit %>% interpreta()                           
```

Todos os valores-p associados aos coeficientes s√£o muito pequenos
(\<0.001), o que significa que podemos rejeitar a hip√≥tese nula para
todos os coeficientes, ao n√≠vel de 5% de confian√ßa. Isso indica que
tanto a for√ßa de trabalho quanto o estoque de capital t√™m efeitos
significativos no PIB, conforme medido pelo logaritmo.

O coeficiente estimado para log(K) √© 0,70728. Isso significa que, se o
estoque de capital (K) aumentar em 1%, o PIB (Y) aumentar√° em
aproximadamente 0.70728 √ó 100 = 70.728 , mantendo todas as outras
vari√°veis constantes.

O coeficiente estimado para log ‚Å° (L ) √©0.29. Isso significa que, se a
for√ßa de trabalho (L) aumentar em 1%, o PIB (Y) aumentar√° em
aproximadamente 0,29 √ó 100 =29,409, mantendo todas as outras vari√°veis
constantes.

Al√©m disso, o modelo tem um R-quadrado ajustado de aproximadamente 0,96,
o que significa que aproximadamente 95,92% da variabilidade no logaritmo
do PIB pode ser explicada pelas vari√°veis independentes inclu√≠das no
modelo.

Esses resultados sugerem que tanto a for√ßa de trabalho quanto o estoque
de capital t√™m um impacto significativo no PIB, conforme medido pelo
logaritmo.

-   **Hip√≥tese Nula** $(H_0)$: $\alpha + \beta = 1$ A soma dos
    coeficientes √© igual a 1, sugerindo retornos constantes √† escala.
-   **Hip√≥tese Alternativa** $(H_1)$: $\alpha + \beta \neq 1$ A soma dos
    coeficientes n√£o √© igual a 1, sugerindo que n√£o h√° retornos
    constantes √† escala.

```{r}
#| tbl-cap: Teste
#| label: tbl-teste1

# Estimar o modelo de regress√£o log-linear
fit = lm(log(Y) ~ log(L) + log(K), data = dta)

# Carregar o pacote necess√°rio
library(knitr)

# Obter as estimativas de alpha e beta
alpha_hat <- coef(fit)["log(L)"]
beta_hat <- coef(fit)["log(K)"]

# Teste de hip√≥tese
soma_alpha_beta <- alpha_hat + beta_hat
se_alpha_beta <- sqrt(vcov(fit)["log(L)", "log(L)"] + vcov(fit)["log(K)", "log(K)"] + 2 * vcov(fit)["log(L)", "log(K)"])

# Calcular a estat√≠stica t
t_statistic <- (soma_alpha_beta - 1) / se_alpha_beta

# Calcular o valor-p
p_value <- 2 * pt(-abs(t_statistic), df = df.residual(fit))

# Criar uma tabela com os resultados
resultados <- data.frame(
  Estat√≠stica = c("Estimativa de alpha", "Estimativa de beta", "Soma de alpha e beta", "Estat√≠stica t", "Valor-p"),
  Valor = c(alpha_hat, beta_hat, soma_alpha_beta, t_statistic, p_value)
)

# Exibir a tabela
kable(resultados, col.names = c("Estat√≠stica", "Valor"), format = "markdown", digits = 4)

```

Na @tbl-teste1, com teste da Teste $ùêª0 : ùõº + ùõΩ = 1$ contra $ùêª1 : ùõº + ùõΩ ‚â† 1$,
obtivemos um valor-p de aproximadamente 0,943. N√£o rejeitamos a hip√≥tese
nula $H_0$ ao n√≠vel de 5% de signific√¢ncia. Isso indica que os dados
n√£o fornecem evid√™ncias suficientes para concluir que a soma de $\alpha$
e $\beta$ √© diferente de 1. Em outras palavras, a suposi√ß√£o de retornos
constantes √† escala $\alpha + \beta = 1$ √© razo√°vel para o ano
analisado. Isso sugere que, com base nos dados, um aumento proporcional
igual na for√ßa de trabalho (L) e no capital (K) resulta em um aumento
proporcional na produ√ß√£o (Y), confirmando a hip√≥tese de retornos
constantes √† escala na fun√ß√£o de produ√ß√£o Cobb-Douglas.

## An√°lise dos Res√≠duos

```{r}
#| label: fig-t3
#| fig-cap: Grafico de An√°lise de res√≠duos 

ggresiduals(fit)
#testResiduals(fit)
```

Com base na an√°lise da tabela @fig-t3, podemos concluir o seguinte sobre
o ajuste do modelo de regress√£o:

**Homocedasticidade:** - A vari√¢ncia dos res√≠duos parece ser constante
em toda a faixa dos valores ajustados, o que √© consistente com a
suposi√ß√£o de homocedasticidade na regress√£o linear.

**Normalidade:** - Embora o teste de Shapiro-Wilk sugira que os res√≠duos
n√£o sigam uma distribui√ß√£o normal, desconsiderando caudas pesadas tanto
nos extremos inferiores quanto nos superiores, podemos aproximar que os
res√≠duos est√£o pr√≥ximos de uma distribui√ß√£o normal.

**Independ√™ncia dos Res√≠duos:** - Tanto o teste de Durbin-Watson quanto
a inspe√ß√£o do gr√°fico de res√≠duos versus valores ajustados na tabela
@fig-t3 n√£o fornecem evid√™ncias significativas para rejeitar a hip√≥tese
nula de aus√™ncia de autocorrela√ß√£o positiva ou negativa nos res√≠duos.
Assim, parece que os res√≠duos s√£o independentes entre si.

**Linearidade:** - N√£o h√° um padr√£o claro nos res√≠duos plotados em
rela√ß√£o aos valores ajustados, indicando linearidade entre as vari√°veis
independentes e dependentes.

Portanto, concluirmos que o modelo de regress√£o parece atender √†s
suposi√ß√µes de homocedasticidade, normalidade aproximada dos res√≠duos,
independ√™ncia dos res√≠duos e linearidade entre as vari√°veis.

# Modelo Logistico

Utilizamos uma base de dados obtida do Kaggle para realizar uma an√°lise
de classifica√ß√£o de cr√©dito. A tarefa principal √© construir um modelo de
machine learning capaz de classificar o cr√©dito dos clientes de uma
institui√ß√£o financeira em diferentes faixas de risco, a fim de otimizar
os processos de decis√£o e reduzir esfor√ßos manuais.

A base de dados cont√©m 50.000 observa√ß√µes e 27 vari√°veis que fornecem
informa√ß√µes detalhadas sobre os clientes, incluindo idade, ocupa√ß√£o,
renda anual, n√∫mero de contas banc√°rias, hist√≥rico de atrasos em
pagamentos, entre outras caracter√≠sticas financeiras. O objetivo
principal √© prever a classifica√ß√£o de cr√©dito dos indiv√≠duos,
segmentando-os em categorias como "Poor" e "Good".

Como parte da an√°lise, ser√° explorado o ajuste do modelo de regress√£o
log√≠stica, focando na avalia√ß√£o dos res√≠duos para verificar a adequa√ß√£o
do modelo. Al√©m disso, ser√£o analisados os Fatores de Infla√ß√£o da
Vari√¢ncia (VIF) para cada preditor, a fim de identificar poss√≠veis
problemas de multicolinearidade e seu impacto na signific√¢ncia das
associa√ß√µes estimadas.

```{r}
## carregando dados: base teste (Kaggle)
## - os dados s√£o carregados no objeto "dta"
dta_teste = read.csv('_dta/test.csv') #credit_scoring
dta_treino = read.csv('_dta/train.csv')

glimpse(dta_treino)

```

```{r}
# Limpeza da base
# Selecionando vari√°veis necess√°rias
dta <- subset(dta_treino, select = c(Credit_Score,Credit_Mix, Outstanding_Debt, Payment_of_Min_Amount, Changed_Credit_Limit))

# Checando valores ausentes
valores_faltantes <-data.frame(sort(colSums(is.na(dta)), decreasing = TRUE))

# Preparando a vari√°vel dependente
dta = dta %>% dplyr::filter(Credit_Score != "Standard")

dta$Credit_Score <- factor(dta$Credit_Score, levels = c('Good', 'Poor'))

# Preparando preditores cont√≠nuos
dta$Outstanding_Debt <- as.numeric(str_extract(dta$Outstanding_Debt, "[0-9.]+"))
dta <- dta[which(dta$Changed_Credit_Limit != "_"), ]
dta$Changed_Credit_Limit <- as.numeric(dta$Changed_Credit_Limit)

# Preparando preditores categ√≥ricos
dta <- dta[which(dta$Credit_Mix != "_"), ]
dta$Credit_Mix <- factor(dta$Credit_Mix, levels = c('Good', 'Standard', 'Bad'))
dta <- dta[which(dta$Payment_of_Min_Amount != "NM"), ]
dta$Payment_of_Min_Amount <- factor(dta$Payment_of_Min_Amount, levels = c('No', 'Yes'))

# An√°lise descritiva
summary(dta)
summary(dta[, c('Outstanding_Debt', 'Changed_Credit_Limit')])

```

```{r}
# An√°lise associativa preliminar
boxplot(Outstanding_Debt ~ Credit_Score, data = dta)
boxplot(Changed_Credit_Limit ~ Credit_Score, data = dta)
chisq.test(x = dta$Credit_Mix, y = dta$Credit_Score)
chisq.test(x = dta$Payment_of_Min_Amount, y = dta$Credit_Score)

```

```{r}
# Modelo de regress√£o log√≠stica
out <- glm(Credit_Score ~ Credit_Mix + Outstanding_Debt + Payment_of_Min_Amount + Changed_Credit_Limit, family = binomial(link = logit), data = dta)
summary(out)
```

### An√°lise dos Res√≠duos

Ao analisar os res√≠duos do modelo log√≠stico ajustado para prever a
classifica√ß√£o de cr√©dito dos indiv√≠duos, observamos que a deviance
residual √© de 24.833 com 32.070 graus de liberdade, comparada √† deviance
nula de 42.604 com 32.075 graus de liberdade. A redu√ß√£o significativa na
deviance indica que o modelo ajusta-se bem aos dados, sugerindo que os
preditores selecionados t√™m um impacto relevante na previs√£o da vari√°vel
resposta. Contudo, uma an√°lise mais detalhada dos res√≠duos seria
necess√°ria para confirmar a aus√™ncia de padr√µes n√£o modelados e avaliar
poss√≠veis viola√ß√µes das suposi√ß√µes do modelo.

### An√°lise do VIF (Variance Inflation Factor)

Para avaliar a multicolinearidade entre os preditores do modelo, foi
realizado o c√°lculo do VIF para cada vari√°vel. A an√°lise dos erros
padr√£o associados aos coeficientes do modelo mostrou que:

-   Credit_MixStandard: Estimativa de 1,010 com erro padr√£o de 0,07013.
-   Credit_MixBad: Estimativa de 2,345 com erro padr√£o de 0,1036.
-   Outstanding_Debt: Estimativa de 0,0006567 com erro padr√£o de
    0,00002935.
-   Payment_of_Min_AmountYes: Estimativa de 1,423 com erro padr√£o de
    0,08047.
-   Changed_Credit_Limit: Estimativa de -0,02382 com erro padr√£o de
    0,003673.

O impacto da multicolinearidade, conforme indicado pelos valores do VIF,
parece ser limitado, uma vez que os erros padr√£o n√£o s√£o excessivamente
inflados. Assim, podemos concluir que a multicolinearidade n√£o exerce um
efeito forte na signific√¢ncia das associa√ß√µes estimadas, mantendo a
confiabilidade das infer√™ncias feitas a partir do modelo.

### Signific√¢ncia das Associa√ß√µes Estimadas

Todas as vari√°veis inclu√≠das no modelo mostraram-se estatisticamente
significativas para prever a classifica√ß√£o de cr√©dito, com p-valores
extremamente baixos (p \< 0,001). As estimativas dos coeficientes
sugerem que:

-   Aumentos no limite de cr√©dito (Changed_Credit_Limit) est√£o
    associados a uma menor probabilidade de um cr√©dito "Poor".
-   Indiv√≠duos com um mix de cr√©dito "Standard" ou "Bad" t√™m uma maior
    chance de ter um cr√©dito classificado como "Poor" em compara√ß√£o com
    aqueles com um mix "Good".
-   O aumento da d√≠vida pendente (Outstanding_Debt) tamb√©m est√°
    associado a uma maior probabilidade de um cr√©dito "Poor".
-   A realiza√ß√£o do pagamento m√≠nimo (Payment_of_Min_AmountYes) est√°
    fortemente associada a uma maior probabilidade de um cr√©dito "Poor".

Esses resultados indicam que as vari√°veis inclu√≠das no modelo s√£o
preditores relevantes e impactam significativamente a classifica√ß√£o de
cr√©dito dos indiv√≠duos.

### An√°lise dos Res√≠duos e Multicolinearidade

Analisamos a deviance e o Fator de Infla√ß√£o da Vari√¢ncia (VIF) para
verificar a adequa√ß√£o do modelo e identificar poss√≠veis problemas de
multicolinearidade.

```{r}
# An√°lise dos res√≠duos
deviance_residual = out$deviance
null_deviance = out$null.deviance
gl_degrees_of_freedom = out$df.residual
gl_null_degrees_of_freedom = out$df.null

cat("Deviance Residual:", deviance_residual, "\n")
cat("Null Deviance:", null_deviance, "\n")
cat("Graus de Liberdade (Modelo):", gl_degrees_of_freedom, "\n")
cat("Graus de Liberdade (Nulo):", gl_null_degrees_of_freedom, "\n")

# VIF (Variance Inflation Factor)
library(car)
vif(out)
```

O gr√°fico de res√≠duos padronizados versus valores preditos apresenta uma
an√°lise visual cr√≠tica para a avalia√ß√£o da adequa√ß√£o do modelo ajustado.
Os res√≠duos padronizados devem idealmente estar distribu√≠dos
aleatoriamente ao redor da linha zero. Observando o gr√°fico, verifica-se
que os res√≠duos n√£o apresentam um padr√£o sistem√°tico, o que sugere que o
modelo est√° ajustado de forma apropriada aos dados. Caso houvesse um
padr√£o vis√≠vel, como uma estrutura em funil ou uma curva, isso poderia
indicar problemas como heterocedasticidade ou n√£o-linearidade, sugerindo
a necessidade de refinamento do modelo.- VOU ADAPTAR NA VERDADE ACHO QUE
O MODELO N T√Å APROPRIADO

### Raz√µes de Chances (Odds Ratios)

```{r}
# Raz√µes de Chances (Odds Ratios)
OR = exp(coef(out))
sink(file = '_out/output/glm_Ex1 (OR).txt')
cat('\n')
print(OR)
sink()
```

### Predi√ß√£o e Avalia√ß√£o do Modelo

```{r}
# Probabilidades preditas
pi.hat = predict(out, type = 'response')

# Escores preditos
cutoff = 0.5
pred.Score = factor(ifelse(pi.hat > cutoff, "Poor", "Good"), levels = c('Good', 'Poor'))

# Matriz de confus√£o
library(caret)
conf_matrix = confusionMatrix(data = pred.Score, reference = dta$Credit_Score)
sink(file = '_out/output/glm_Ex1 (confMat).txt')
cat('\n')
print(conf_matrix)
sink()

# Curva ROC
library(pROC)
ROC = roc(dta$Credit_Score ~ pi.hat)
plot(ROC, print.auc = TRUE)
# Salvando figura
dev.print(file = '_out/figures/figEx1_ROC.png', device = png, width = 1280, height = 720, res = 96, units = 'px')
```

### An√°lise dos Resultados

A an√°lise dos resultados mostra que o modelo de regress√£o log√≠stica
ajusta-se bem aos dados, com uma redu√ß√£o significativa na deviance em
rela√ß√£o √† deviance nula. A an√°lise do VIF indica que a
multicolinearidade n√£o afeta substancialmente a signific√¢ncia das
vari√°veis preditoras. As raz√µes de chances e as m√©tricas de performance,
como a curva ROC e a matriz de confus√£o, fornecem uma vis√£o clara da
efic√°cia do modelo em classificar a qualidade do cr√©dito.- VOU ADAPTAR
ESSE TEXTO

# Modelo Gama Log-Linear

```{r}
interpreta <- function(mod, alpha = 0.05) {
  tab <- summary(mod)
  tabela <- as.data.frame(coef(tab))
  tabela <- cbind(Covariavel = rownames(tabela), tabela)
  tabela <- tabela %>%
    mutate(
      Estimacao = round(Estimate,4),
      ErroPadrao = round(`Std. Error`,4),
      Pvalor = `Pr(>|t|)`,
      sig = case_when(
        is.na(`Pr(>|t|)`) ~ " ",
        `Pr(>|t|)` < 0.001 ~ "<0.001***",
        `Pr(>|t|)` <= alpha ~ paste0(" ", format(`Pr(>|t|)`, digits = 3), "*"),
        TRUE ~ paste0(" ", format(`Pr(>|t|)`, digits = 3))
      )
    ) %>%
    select(Estimacao, ErroPadrao, Pvalor, sig)
  
  return(tabela)
}

```

```{r}
dta = read_dta("_dta/pwt1001.dta")
# filtrando para 2014
dta = dta %>% subset(year == '2014')
```

```{r}
## criando as vari√°veis de interesse
# definindo as vari√°veis
dta$Y = dta$rgdpo
dta$L = dta$emp*dta$hc
dta$K = dta$rnna
# rearranjando colunas
dta = dta %>% relocate(Y, .after = year)
dta = dta %>% relocate(L, .after = Y)
dta = dta %>% relocate(K, .after = K)
# filtrando NAs
df.complete = dta[, c('Y', 'L', 'K')] %>% na.omit()
dta = merge(df.complete, dta, all.x = TRUE)


```

```{r}
#| tbl-cap: Modelo Gamma Log-linear
#| label: tbl-gama2

# Ajuste o modelo gama log-linear
fit_gamma <- glm(log(Y) ~ log(L) + log(K), family = Gamma(link = "log"), data = dta)




# Exiba os resultados
fit_gamma  %>% interpreta()   

```

O intercepto estimado de 1.61754583 (@tbl-gama2) representa o logaritmo
da produ√ß√£o quando tanto o trabalho (L) quanto o capital (K) s√£o iguais
a 1. Com um valor-p extremamente pequeno, o intercepto √©
estatisticamente significativo, indicando que ele desempenha um papel
importante na modelagem da vari√°vel dependente ùëåùëñ, ao n√≠vel de 5% de
signific√¢ncia.

O coeficiente para log(L) √© 0.02371488, indicando que um aumento de 1%
na for√ßa de trabalho (L) leva a um aumento de aproximadamente 0.024% na
produ√ß√£o, mantendo o capital constante. O valor-p extremamente pequeno
indica que este coeficiente √© altamente significativo, o que valida a
import√¢ncia da for√ßa de trabalho na determina√ß√£o da produ√ß√£o no modelo.

O coeficiente para log(K) √© 0.06012190, sugerindo que um aumento de 1%
no capital (K) resulta em um aumento de aproximadamente 0.060% na
produ√ß√£o, mantendo a for√ßa de trabalho constante. Com um valor-p
extremamente baixo, esse coeficiente √© altamente significativo,
demonstrando que o capital tem uma influ√™ncia importante e
estatisticamente significativa na produ√ß√£o.

O par√¢metro de dispers√£o estimado √© 0.00135537, o que indica que h√° uma
baixa variabilidade dos dados em torno da m√©dia ajustada pelo modelo.
Isso sugere que o modelo gamma log-linear est√° capturando bem a
dispers√£o dos dados, com pouca heterogeneidade residual n√£o explicada
pelo modelo.

```{r}
# Estimativa dos coeficientes e vari√¢ncias
alpha_hat <- coef(fit_gamma )["log(L)"]
beta_hat <- coef(fit_gamma )["log(K)"]

# C√°lculo da soma dos coeficientes
soma_alpha_beta <- alpha_hat + beta_hat

# C√°lculo do erro padr√£o da soma dos coeficientes
vcov_matrix <- vcov(fit_gamma )
se_alpha_beta <- sqrt(vcov_matrix["log(L)", "log(L)"] + vcov_matrix["log(K)", "log(K)"] + 2 * vcov_matrix["log(L)", "log(K)"])

# C√°lculo da estat√≠stica t
t_statistic <- (soma_alpha_beta - 1) / se_alpha_beta

# C√°lculo do valor-p
p_value <- 2 * pt(-abs(t_statistic), df = df.residual(fit_gamma ))






```

```{r}
#| tbl-cap: ""
#| label: tbl-teste

# Criando a tabela de resultados
resultados <- data.frame(
  Descri√ß√£o = c("Soma de alpha e beta", "Erro padr√£o", "Estat√≠stica t", "Valor-p", "Decis√£o"),
  Valor = c(
    round(soma_alpha_beta,4),
    round(se_alpha_beta,4),
    round(t_statistic,4),
    p_value,
    ifelse(p_value < 0.05, "Rejeitamos H0", "N√£o rejeitamos H0")
  )
)

# Exibir a tabela
kable(resultados)

```

Decis√£o sobre Teste $ùêª0 : ùõº + ùõΩ = 1$ contra $ùêª1 : ùõº + ùõΩ ‚â† 1$: (@tbl-teste) Como o valor-p √© extremamente pequeno, rejeitamos a hip√≥tese nula $H_0$ indicando que a soma de $\alpha$ e $\beta$ √© significativamente diferente de 1. Isso
significa que a hip√≥tese de retornos constantes √† escala n√£o √© v√°lida
para os dados analisados.

Retornos constantes √† escala implicam que, se ambos os insumos (L e K)
aumentarem na mesma propor√ß√£o, a produ√ß√£o $Y_i$ tamb√©m aumentar√° na
mesma propor√ß√£o. No entanto, dado que a soma de $\alpha$ e $\beta$ √©
significativamente diferente de 1, isso sugere que os retornos √† escala
n√£o s√£o constantes para este modelo. Dependendo do valor espec√≠fico da
soma $(\alpha + \beta < 1$ ou $\alpha + \beta > 1)$, os retornos √†
escala podem ser decrescentes ou crescentes, respectivamente.

Assim, a soma de $\alpha$ e $\beta$ √© 0.08383678, o que est√° longe de 1,
indicando retornos decrescentes √† escala. Isso significa que aumentar
proporcionalmente a for√ßa de trabalho e o capital levar√° a um aumento
menos que proporcional na produ√ß√£o. Em outras palavras, conforme mais
insumos s√£o adicionados, a produtividade marginal desses insumos
diminui, levando a um crescimento menos eficiente da produ√ß√£o.

## An√°lise dos Res√≠duos

```{r}
#| label: tbl-gamma1
#| tbl-cap: Grafico de An√°lise de res√≠duos 

library(lmtest)
ggresiduals(fit_gamma )
```

```{r,include=FALSE}

bptest(fit_gamma)

# Teste de Durbin-Watson
dw_test <- dwtest(fit_gamma)
print(dw_test)
```

Com base na an√°lise da tabela @tbl-gamma1, podemos concluir o seguinte
sobre o ajuste do modelo de regress√£o:

**Homocedasticidade:** - A vari√¢ncia dos res√≠duos parece ser constante
em toda a faixa dos valores ajustados. Com o teste de Teste de
Breusch-Paga, com um valor-p de 0.2634, n√£o rejeitamos a hip√≥tese nula
de homocedasticidade. Isso significa que n√£o h√° evid√™ncias suficientes
para sugerir a presen√ßa de heterocedasticidade nos res√≠duos do modelo
gamma.

**Normalidade:** - Embora o teste de Shapiro-Wilk sugira que os res√≠duos
n√£o sigam uma distribui√ß√£o normal, desconsiderando caudas pesadas tanto
nos extremos inferiores quanto nos superiores, podemos aproximar que os
res√≠duos est√£o pr√≥ximos de uma distribui√ß√£o normal.

**Independ√™ncia dos Res√≠duos:** - Tanto o teste de Durbin-Watson quanto
a inspe√ß√£o do gr√°fico de res√≠duos versus valores ajustados na tabela
@tbl-gamma1 n√£o fornecem evid√™ncias significativas para rejeitar a
hip√≥tese nula de aus√™ncia de autocorrela√ß√£o positiva ou negativa nos
res√≠duos. Assim, parece que os res√≠duos s√£o independentes entre si, o
que √© uma boa indica√ß√£o de que o modelo est√° adequadamente ajustado
quanto a essa suposi√ß√£o.

**Linearidade:** - H√° um padr√£o claro nos res√≠duos plotados em rela√ß√£o
aos valores ajustados, indicando n√£o linearidade entre as vari√°veis
independentes e dependentes.

```{r,include=FALSE}
# Obter o log-likelihood dos modelos
logLik(fit_gamma)
logLik(fit)

```

```{r,include=FALSE}
# Obter o AIC dos modelos
AIC(fit_gamma)
AIC(fit)

```

```{r,include=FALSE}
# Obter o BIC dos modelos
BIC(fit_gamma)
BIC(fit)

```

# Compara√ß√£o dos Modelos: Gamma Log-Linear vs. Modelo Normal

Log-Likelihood (Log-Verossimilhan√ßa) - **Modelo Gamma Log-Linear**:
-83.07791 - **Modelo Normal**: -59.39108

O valor de log-likelihood mais alto (menos negativo) indica um melhor
ajuste do modelo aos dados. O modelo normal tem um valor de
log-likelihood mais alto, sugerindo que se ajusta melhor aos dados em
compara√ß√£o com o modelo Gamma log-linear.

Crit√©rio de Informa√ß√£o de Akaike (AIC) - **Modelo Gamma Log-Linear**:
174.1558 - **Modelo Normal**: 126.7822

Valores menores de AIC indicam um modelo mais eficiente em termos de
ajuste aos dados com penaliza√ß√£o pela complexidade. O modelo normal
apresenta um AIC significativamente menor, indicando que √© mais
eficiente e se ajusta melhor aos dados do que o modelo Gamma log-linear.

Crit√©rio de Informa√ß√£o de Bayes (BIC) - **Modelo Gamma Log-Linear**:
186.0351 - **Modelo Normal**: 138.6614

O BIC tamb√©m penaliza a complexidade do modelo e valores menores indicam
um ajuste melhor com menor penaliza√ß√£o por complexidade. Novamente, o
modelo normal apresenta um BIC significativamente menor, refor√ßando que
√© mais adequado para os dados em compara√ß√£o ao modelo Gamma log-linear.

Com base nos crit√©rios de log-likelihood, AIC e BIC, o **modelo normal**
√© a melhor escolha. Ele n√£o s√≥ se ajusta melhor aos dados (conforme
indicado pelo log-likelihood), mas tamb√©m √© mais eficiente e simples em
termos de complexidade (conforme indicado pelos valores de AIC e BIC).

Portanto, o modelo normal √© prefer√≠vel ao modelo Gamma log-linear para a
an√°lise dos seus dados, oferecendo um melhor equil√≠brio entre ajuste e
complexidade.
