---
title: "Trabalho MLG"
subtitle: ""
author: "Eliana Cardoso Gonçalves e Sophia Araujo de Moraes"
date: "08/26/2024"
date-format: short # formatação dd/mm/aaaa
lang: pt # linguagem
toc: true # índice
number-sections: true
fig-cap-location: top # localização título figura 
geometry:
  - top=3cm
  - left=3cm
  - right=2cm
  - bottom=2cm
tbl-cap-location: top
df-print: kable # saída dos data frames serem kable
fig-width: 10
fig-height: 4
format: 
  html:
    self-contained: true # tornar o html compartilhável
    theme: flatly
  pdf: 
    documentclass: scrreprt
    margin: 1in
  docx: default
editor:
  markdown:
    wrap: 72
editor_options:
  chunk_output_type: console
output: 
  pdf_document:
    fig_caption: true
    df_print: kable
  word_document:
    fig_caption: true
    df_print: kable
prefer-html: true
execute:
  echo: false
  warning: false
---

```{r}
rm(list = ls())

if(!require(remotes)) install.packages("remotes")
remotes::install_github("fndemarqui/reglin")
```

```{r, include=FALSE}
#install.packages("tinytex")
library(tinytex)
#tinytex::install_tinytex()  # Para instalar uma distribuição LaTeX mínima

#install.packages("flextable")
library(flextable)
#install.packages("rmarkdown")
library(rmarkdown)
```

```{r,biblioteca}


if (!require(pacman))(install.packages("pacman"))(require(pacman))
pacman::p_load( kableExtra, corrplot, haven, ggplot2, 
  tidyverse, performance, see, car, 
  knitr, patchwork, summarytools, 
  caret, pROC, dplyr, reglin, dplyr)

```

```{r,diretorio}

source("_src/src.R")

```

# Dados da Penn World Table de 2020

Dois tópicos desse estudo (MODELO LINEAR NORMAL e MODELO GAMA
LOG-LINEAR) se concentram em uma amostra de 183 países distintos no ano
de 2014. Os dois modelos foram utilizados para explorar como a força de
trabalho e o estoque de capital influenciam o PIB, desse modo por meio
de regressões lineares múltiplas, será estimado os coeficientes que
quantificam essas relações, permitindo-nos compreender melhor os
determinantes do crescimento econômico.

Essa relação pode ser expressa pela seguinte equação:

$$Y=β0+β1X1+β2X2+...+βpXp+ε$$

Onde:

-   $Y$ é a variável dependente ( PIB Nacional (Y) em dólares PPP de
    2014).

-   $X1,X2,...,Xp$ são as variáveis independentes ( Força de Trabalho
    (L)e o Estoque de Capital (K) em dólares PPP de 2014).

-   $β1,β2,...,βp$ são os coeficientes de regressão que representam os
    efeitos das variáveis independentes na variável dependente.

-   $ε$ é o termo de erro, que representa a variação não explicada pelo
    modelo.

Para complementar a análise, é importante entender como os dois modelos
— o Modelo Linear Normal e o Modelo Gama Log-Linear — foram utilizados
para explorar as relações entre o PIB nacional, a força de trabalho e o
estoque de capital. Esses modelos oferecem diferentes abordagens para
analisar os dados e podem fornecer insights valiosos sobre os fatores
que impulsionam o crescimento econômico:

**Modelo Linear Normal**: O Modelo Linear Normal é uma aplicação
clássica da regressão linear múltipla. Neste contexto, assume-se que a
relação entre as variáveis independentes (força de trabalho e estoque de
capital) e a variável dependente (PIB) é linear. Isso significa que cada
incremento em uma variável independente resulta em um aumento ou
diminuição constante na variável dependente, dependendo do sinal e do
valor dos coeficientes de regressão.

Este modelo é baseado em algumas suposições, como a normalidade dos
resíduos, homocedasticidade (ou seja, a variância constante dos
resíduos), e a ausência de multicolinearidade entre as variáveis
independentes. Quando essas suposições são satisfeitas, o Modelo Linear
Normal fornece estimativas consistentes e eficientes dos coeficientes de
regressão, permitindo uma compreensão clara de como cada fator contribui
para o PIB.

**Modelo Gama Log-Linear**: Por outro lado, o Modelo Gama Log-Linear
oferece uma abordagem alternativa, especialmente útil quando os dados
não atendem às suposições de normalidade e homocedasticidade do modelo
linear. Este modelo é particularmente apropriado para situações onde a
variável dependente (PIB) assume valores positivos e pode apresentar uma
distribuição assimétrica, o que é comum em dados econômicos.

No Modelo Gama Log-Linear, a transformação logarítmica é aplicada à
variável dependente. Isso permite capturar relações não lineares entre o
PIB e as variáveis independentes, como a força de trabalho e o estoque
de capital. A distribuição Gama, utilizada nesse modelo, é adequada para
modelar a variável dependente em casos onde há heterocedasticidade — ou
seja, quando a variabilidade dos dados aumenta com o valor previsto.

Essa abordagem é especialmente útil para capturar efeitos
multiplicativos, onde as variáveis independentes influenciam a variável
dependente de forma proporcional, em vez de aditiva. O Modelo Gama
Log-Linear pode, portanto, revelar nuances e complexidades na relação
entre os fatores estudados e o crescimento econômico que o modelo linear
normal pode não captar.

## Modelo Linear Normal

```{r}
dta = read_dta("_dta/pwt1001.dta")
# filtrando para 2014
dta = dta %>% subset(year == '2014')
```

```{r}
## criando as variáveis de interesse
# definindo as variáveis
dta$Y = dta$rgdpo
dta$L = dta$emp*dta$hc
dta$K = dta$rnna
# rearranjando colunas
dta = dta %>% relocate(Y, .after = year)
dta = dta %>% relocate(L, .after = Y)
dta = dta %>% relocate(K, .after = K)
# filtrando NAs
df.complete = dta[, c('Y', 'L', 'K')] %>% na.omit()
dta = merge(df.complete, dta, all.x = TRUE)


```

```{r}
#| label: tbl-t1
#| tbl-cap: Tabela Resumo das Variáveis Y, L e K.

descr_stats <- descr(dta[, c('Y', 'L', 'K')], 
                     stats = c("mean", "sd", "min", "med", "max"), 
                     transpose = FALSE, 
                     headings = FALSE)

# Convertendo para um dataframe para facilitar a manipulação
descr_df <- as.data.frame(descr_stats)

# Adicionando a coluna de Estatísticas
descr_df <- descr_df %>%
  dplyr::select( everything())

# Exibindo a tabela formatada em markdown
library(knitr)
kable(descr_df, format = "markdown")%>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necessário


```

```{r}
#| label: fig-y
#| fig-cap: Histograma PIB Nacional (Y) em dólares PPP de 2014
p <- ggplot(dta, aes(x = Y)) +
  # Histograma
  geom_histogram(aes(y = after_stat(density)), fill = 'lightblue', color = 'black', bins = 10) +
  # Distribuição normal (para comparação)
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$Y, na.rm = TRUE), sd = sd(dta$Y, na.rm = TRUE))) +
  # Label eixo x
  xlab('Y') +
  # Label eixo y
  ylab('Density') +
  # Tema do plot
  theme(
    # Painel
    panel.background = element_blank(),
    panel.border = element_blank(),
    # Eixos
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )
p
```

Observando o @fig-y e @tbl-t1 , o valor mínimo do PIB é \$2.569,
enquanto o valor máximo é significativamente maior, chegando a
\$18.244.220, indicando uma grande variação no PIB entre os países da
amostra.A média do PIB é \$769.941, o que é substancialmente maior que a
mediana de \$123.419, sugerindo que alguns países com PIB muito alto
estão puxando a média para cima. A distribuição do PIB é bastante
assimétrica, com muitos países tendo PIBs relativamente baixos e poucos
países com PIBs muito altos.

```{r}
#| label: fig-l
#| fig-cap: Histograma Força de Trabalho (L)


p = ggplot(dta, aes(x = L)) +
  # histograma
  geom_histogram(aes(x = L, after_stat(density)), fill = 'lightblue', col = 'black', bins = 10) +
  # dist. normal (p/ comparação)
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$L), sd = sd(dta$L))) + 
  # label eixo x
  xlab('L') +
  # label eixo y
  ylab('Density') +
  # tema do plot
  theme(
    # painel
    panel.background = element_blank(),
    panel.border = element_blank(),
    # eixos
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )
p

```

Analisando o @fig-l e a @tbl-t1, a variação da força de trabalho de
0,2994 a 2.045,91 reflete uma grande disparidade na população
economicamente ativa entre os países. Com uma média de 54,60 e uma
mediana de 11,65, a distribuição mostra-se assimétrica, sugerindo a
presença de países com forças de trabalho extremas, seja pela sua
grandeza ou pequenez em relação à média da amostrm alguns países com
países com a força de trabalho outlier.

```{r}
#| fig-cap: Histograma Estoque de Capital (K) em dólares PPP de 2014)
#| label: fig-k


p = ggplot(dta, aes(x = K)) +
  # histograma
  geom_histogram(aes(x = K, after_stat(density)), fill = 'lightblue', col = 'black', bins = 10) +
  # dist. normal (p/ comparação)
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$K), sd = sd(dta$K))) + 
  # label eixo x
  xlab('K') +
  # label eixo y
  ylab('Density') +
  # tema do plot
  theme(
    # painel
    panel.background = element_blank(),
    panel.border = element_blank(),
    # eixos
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )
p

```

Analisando os valores da @tbl-t1 e @fig-k , observamos que o estoque de
capital varia amplamente, de \$7.345 a \$64.118.472, indicando
diferenças significativas no nível de investimento em capital produtivo
entre os países.

A média do estoque de capital é \$3.058.761, consideravelmente maior que
a mediana de \$394.841, o que sugere que alguns países têm estoques de
capital extremamente altos que estão elevando a média.

### Resultados

Para garantir a robustez e confiabilidade dos resultados, optamos por
realizar uma transformação log-log nas variáveis, considerando que o PIB
Nacional (Y) em dólares PPP de 2014, juntamente com as variáveis
independentes "força de trabalho" e "estoque de capital", não apresentam
uma distribuição normal. Essa abordagem vai permitir que aos
pressupostos do modelo normal sejam atendidos e obter resultados mais
consistentes.

Ao aplicar a transformação log-log, estamos ajustando a distribuição das
variáveis para se adequarem melhor ao modelo, mitigando quaisquer
distorções ou viés que possam surgir devido à falta de normalidade. Isso
nos permite realizar inferências estatísticas mais confiáveis e
interpretar os efeitos das variáveis independentes sobre o PIB Nacional
de forma mais precisa.

```{r}
# Aplicar transformação logarítmica
dta$log_Y <- log(dta$Y)
dta$log_L <- log(dta$L)
dta$log_K <- log(dta$K)


# Histogramas

# Histograma log do PIB Nacional (log_Y)
p_log_Y <- ggplot(dta, aes(x = log_Y)) +
  geom_histogram(aes(y = after_stat(density)), fill = 'lightblue', color = 'black', bins = 10) +
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$log_Y, na.rm = TRUE), sd = sd(dta$log_Y, na.rm = TRUE)),
                color = 'red', linewidth = 1) +
  xlab('log(Y)') +
  ylab('Density') +
  theme(
    panel.background = element_blank(),
    panel.border = element_blank(),
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )

# Histograma log da Força de Trabalho (log_L)
p_log_L <- ggplot(dta, aes(x = log_L)) +
  geom_histogram(aes(y = after_stat(density)), fill = 'lightblue', color = 'black', bins = 10) +
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$log_L, na.rm = TRUE), sd = sd(dta$log_L, na.rm = TRUE)),
                color = 'red', linewidth = 1) +
  xlab('log(L)') +
  ylab('Density') +
  theme(
    panel.background = element_blank(),
    panel.border = element_blank(),
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )

# Histograma log do Estoque de Capital (log_K)
p_log_K <- ggplot(dta, aes(x = log_K)) +
  geom_histogram(aes(y = after_stat(density)), fill = 'lightblue', color = 'black', bins = 10) +
  stat_function(fun = dnorm,
                args = list(mean = mean(dta$log_K, na.rm = TRUE), sd = sd(dta$log_K, na.rm = TRUE)),
                color = 'red', linewidth = 1) +
  xlab('log(K)') +
  ylab('Density') +
  theme(
    panel.background = element_blank(),
    panel.border = element_blank(),
    axis.line.x = element_line(linewidth = 0.5, linetype = "solid", colour = "black"),
    axis.line.y = element_line(linewidth = 0.5, linetype = "solid", colour = "black")
  )

# Exibir os gráficos
p_log_Y

```

```{r}

p_log_L

```

```{r}

p_log_K

```

Essa estratégia de transformação aumenta a robustez da análise, pois
reduz a influência de valores extremos e torna os resultados menos
sensíveis a distribuições não normais. Portanto, podemos ter maior
confiança nas conclusões derivadas do modelo, garantindo uma abordagem
metodológica sólida e resultados mais confiáveis para tomada de decisão.

A análise macroeconômica é fundamental para entender o desenvolvimento
econômico e social dos países. No contexto da contabilidade nacional,
variáveis como o Produto Interno Bruto (PIB), a força de trabalho e o
estoque de capital são essenciais para avaliar a produtividade e o
crescimento econômico. Este estudo utiliza dados da Penn World Table de
2020 para investigar a relação entre essas variáveis.

O PIB nacional (Y), medido em dólares PPC de 2014, é uma medida
abrangente da atividade econômica de um país. A força de trabalho (L)
representa o total de pessoas empregadas ou em busca de emprego,
refletindo a capacidade produtiva humana. O estoque de capital (K),
também medido em dólares PPC de 2014, indica o valor total dos ativos
produtivos de um país, como máquinas, edifícios e infraestrutura.

Ao analisar essas variáveis, o objetivo é fornecer insights sobre as
políticas econômicas que podem fomentar o crescimento e a produtividade.
Esta investigação pode ajudar formuladores de políticas, economistas e
pesquisadores a identificar áreas-chave para intervenção e investimento,
promovendo um desenvolvimento econômico sustentável e inclusivo.

```{r}
interpreta <- function(mod, alpha = 0.05) {
  tab <- summary(mod)
  tabela <- as.data.frame(coef(tab))
  tabela <- cbind(Covariavel = rownames(tabela), tabela)
  tabela <- tabela %>%
    mutate(
      Estimação = Estimate,
      Pvalor = `Pr(>|t|)`,
      sig = case_when(
        is.na(`Pr(>|t|)`) ~ " ",
        `Pr(>|t|)` < 0.001 ~ "<0.001***",
         `Pr(>|t|)` <= alpha ~ paste0(" ", format(`Pr(>|t|)`, digits = 3), "*"),
        TRUE ~ paste0(" ", format(`Pr(>|t|)`, digits = 3))
      )
    ) %>%
    dplyr::select( Estimação, Pvalor, sig)
  
  return(tabela)
}
```

```{r}
#| label: tbl-t2
#| tbl-cap: Ajuste do Modelo de Regressão Log-Normal 

fit = lm(log(Y) ~ log(L) + log(K), data = dta)


fit %>% interpreta()                           
```

Todos os p-valores associados aos coeficientes são muito pequenos
(\<0.001), o que significa que podemos rejeitar a hipótese nula para
todos os coeficientes, ao nível de 5% de confiança. Isso indica que
tanto a força de trabalho quanto o estoque de capital têm efeitos
significativos no PIB, conforme medido pelo logaritmo.

O coeficiente estimado para log(K) é 0,70728. Isso significa que, se o
estoque de capital (K) aumentar em 1%, o PIB (Y) aumentará em
aproximadamente 0.70728 × 100 = 70.728 , mantendo todas as outras
variáveis constantes.

O coeficiente estimado para log ⁡ (L ) é0.29. Isso significa que, se a
força de trabalho (L) aumentar em 1%, o PIB (Y) aumentará em
aproximadamente 0,29 × 100 =29,409, mantendo todas as outras variáveis
constantes.

Além disso, o modelo tem um R-quadrado ajustado de aproximadamente 0,96,
o que significa que aproximadamente 95,92% da variabilidade no logaritmo
do PIB pode ser explicada pelas variáveis independentes incluídas no
modelo.

Esses resultados sugerem que tanto a força de trabalho quanto o estoque
de capital têm um impacto significativo no PIB, conforme medido pelo
logaritmo.

-   **Hipótese Nula** $(H_0)$: $\alpha + \beta = 1$ A soma dos
    coeficientes é igual a 1, sugerindo retornos constantes à escala.
-   **Hipótese Alternativa** $(H_1)$: $\alpha + \beta \neq 1$ A soma dos
    coeficientes não é igual a 1, sugerindo que não há retornos
    constantes à escala.

```{r}
#| tbl-cap: Teste
#| label: tbl-teste1

# Estimar o modelo de regressão log-linear
fit = lm(log(Y) ~ log(L) + log(K), data = dta)

# Carregar o pacote necessário
library(knitr)

# Obter as estimativas de alpha e beta
alpha_hat <- coef(fit)["log(L)"]
beta_hat <- coef(fit)["log(K)"]

# Teste de hipótese
soma_alpha_beta <- alpha_hat + beta_hat
se_alpha_beta <- sqrt(vcov(fit)["log(L)", "log(L)"] + vcov(fit)["log(K)", "log(K)"] + 2 * vcov(fit)["log(L)", "log(K)"])

# Calcular a estatística t
t_statistic <- (soma_alpha_beta - 1) / se_alpha_beta

# Calcular o valor-p
p_value <- 2 * pt(-abs(t_statistic), df = df.residual(fit))

# Criar uma tabela com os resultados
resultados <- data.frame(
  Estatística = c("Estimativa de alpha", "Estimativa de beta", "Soma de alpha e beta", "Estatística t", "Valor-p"),
  Valor = c(alpha_hat, beta_hat, soma_alpha_beta, t_statistic, p_value)
)

# Exibir a tabela
kable(resultados, col.names = c("Estatística", "Valor"), format = "markdown", digits = 4)%>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necessário


```

Na @tbl-teste1, com teste da Teste $𝐻0 : 𝛼 + 𝛽 = 1$ contra
$𝐻1 : 𝛼 + 𝛽 ≠ 1$, obtivemos um p-valor de aproximadamente 0,943. Não
rejeitamos a hipótese nula $H_0$ ao nível de 5% de significância. Isso
indica que os dados não fornecem evidências suficientes para concluir
que a soma de $\alpha$ e $\beta$ é diferente de 1. Em outras palavras, a
suposição de retornos constantes à escala $\alpha + \beta = 1$ é
razoável para o ano analisado. Isso sugere que, com base nos dados, um
aumento proporcional igual na força de trabalho (L) e no capital (K)
resulta em um aumento proporcional na produção (Y), confirmando a
hipótese de retornos constantes à escala na função de produção
Cobb-Douglas.

### Análise dos Resíduos

```{r}
#| label: fig-t3
#| fig-cap: Grafico de Análise de resíduos 

ggresiduals(fit)
#testResiduals(fit)
```

```{r}
#testResiduals(fit)

# Criando o data frame com os resultados dos testes
test_results <- data.frame(
  Teste = c("Shapiro-Wilk Normality Test", 
            "Non-constant Variance Score Test", 
            "Durbin-Watson Test for Autocorrelated Errors"),
  Estatística = c("W = 0.96", 
                  "Chisquare = 5.338458", 
                  "D-W Statistic = 2.133801"),
  `p-valor` = c(0.0003379, 0.02086, 0.42))

kable(test_results, caption = "Resultados dos Testes de Resíduos") %>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necessário


```

Com base na análise da tabela @fig-t3, podemos concluir o seguinte sobre
o ajuste do modelo de regressão:

**Homocedasticidade:** - A variância dos resíduos parece ser constante
em toda a faixa dos valores ajustados, o que é consistente com a
suposição de homocedasticidade na regressão linear.

**Normalidade:** - Embora o teste de Shapiro-Wilk sugira que os resíduos
não sigam uma distribuição normal, desconsiderando caudas pesadas tanto
nos extremos inferiores quanto nos superiores, podemos aproximar que os
resíduos estão próximos de uma distribuição normal.

**Independência dos Resíduos:** - Tanto o teste de Durbin-Watson quanto
a inspeção do gráfico de resíduos versus valores ajustados na tabela
@fig-t3 não fornecem evidências significativas para rejeitar a hipótese
nula de ausência de autocorrelação positiva ou negativa nos resíduos.
Assim, parece que os resíduos são independentes entre si.

**Linearidade:** - Não há um padrão claro nos resíduos plotados em
relação aos valores ajustados, indicando linearidade entre as variáveis
independentes e dependentes.

Portanto, concluirmos que o modelo de regressão parece atender às
suposições de homocedasticidade, normalidade aproximada dos resíduos,
independência dos resíduos e linearidade entre as variáveis.

## Modelo Gama Log-Linear

### Resultados

Utilizamos o mesmo banco de dados do Modelo de Log-Normal.Por meio da
tabela abaixo é possível verificar como foi o ajuste das variáveis ao
modelo de gama log-linear:

```{r}
interpreta <- function(mod, alpha = 0.05) {
  tab <- summary(mod)
  tabela <- as.data.frame(coef(tab))
  tabela <- cbind(Covariavel = rownames(tabela), tabela)
  tabela <- tabela %>%
    mutate(
      Estimacao = round(Estimate,4),
      ErroPadrao = round(`Std. Error`,4),
      Pvalor = `Pr(>|t|)`,
      sig = case_when(
        is.na(`Pr(>|t|)`) ~ " ",
        `Pr(>|t|)` < 0.001 ~ "<0.001***",
        `Pr(>|t|)` <= alpha ~ paste0(" ", format(`Pr(>|t|)`, digits = 3), "*"),
        TRUE ~ paste0(" ", format(`Pr(>|t|)`, digits = 3))
      )
    ) %>%
    dplyr::select(Estimacao, ErroPadrao, Pvalor, sig)
  
  return(tabela)
}

```

```{r}
dta = read_dta("_dta/pwt1001.dta")
# filtrando para 2014
dta = dta %>% subset(year == '2014')
```

```{r}
## criando as variáveis de interesse
# definindo as variáveis
dta$Y = dta$rgdpo
dta$L = dta$emp*dta$hc
dta$K = dta$rnna
# rearranjando colunas
dta = dta %>% relocate(Y, .after = year)
dta = dta %>% relocate(L, .after = Y)
dta = dta %>% relocate(K, .after = K)
# filtrando NAs
df.complete = dta[, c('Y', 'L', 'K')] %>% na.omit()
dta = merge(df.complete, dta, all.x = TRUE)


```

```{r}
#| tbl-cap: Modelo Gamma Log-linear
#| label: tbl-gama2

# Ajuste o modelo gama log-linear
fit_gamma <- glm(log(Y) ~ log(L) + log(K), family = Gamma(link = "log"), data = dta)

# Exiba os resultados
fit_gamma  %>% interpreta()   

```

O intercepto estimado de 1.61754583 (@tbl-gama2) representa o logaritmo
da produção quando tanto o trabalho (L) quanto o capital (K) são iguais
a 1. Com um p-valor extremamente pequeno, o intercepto é
estatisticamente significativo, indicando que ele desempenha um papel
importante na modelagem da variável dependente 𝑌𝑖, ao nível de 5% de
significância.

O coeficiente para log(L) é 0.02371, indicando que um aumento de 1% na
força de trabalho (L) leva a um aumento de aproximadamente 0.024% na
produção, mantendo o capital constante. O p-valor extremamente pequeno
indica que este coeficiente é altamente significativo, o que valida a
importância da força de trabalho na determinação da produção no modelo.

O coeficiente para log(K) é 0.06012, sugerindo que um aumento de 1% no
capital (K) resulta em um aumento de aproximadamente 0.060% na produção,
mantendo a força de trabalho constante. Com um p-valor extremamente
baixo, esse coeficiente é altamente significativo, demonstrando que o
capital tem uma influência importante e estatisticamente significativa
na produção.

O parâmetro de dispersão estimado é 0.00135, o que indica que há uma
baixa variabilidade dos dados em torno da média ajustada pelo modelo.
Isso sugere que o modelo gamma log-linear está capturando bem a
dispersão dos dados, com pouca heterogeneidade residual não explicada
pelo modelo.

```{r}
# Estimativa dos coeficientes e variâncias
alpha_hat <- coef(fit_gamma )["log(L)"]
beta_hat <- coef(fit_gamma )["log(K)"]

# Cálculo da soma dos coeficientes
soma_alpha_beta <- alpha_hat + beta_hat

# Cálculo do erro padrão da soma dos coeficientes
vcov_matrix <- vcov(fit_gamma )
se_alpha_beta <- sqrt(vcov_matrix["log(L)", "log(L)"] + vcov_matrix["log(K)", "log(K)"] + 2 * vcov_matrix["log(L)", "log(K)"])

# Cálculo da estatística t
t_statistic <- (soma_alpha_beta - 1) / se_alpha_beta

# Cálculo do valor-p
p_value <- 2 * pt(-abs(t_statistic), df = df.residual(fit_gamma ))


```

```{r}
#| tbl-cap: Teste
#| label: tbl-teste

# Criando a tabela de resultados
resultados <- data.frame(
  Descrição = c("Soma de alpha e beta", "Erro padrão", "Estatística t", "Valor-p", "Decisão"),
  Valor = c(
    round(soma_alpha_beta,4),
    round(se_alpha_beta,4),
    round(t_statistic,4),
    p_value,
    ifelse(p_value < 0.05, "Rejeitamos H0", "Não rejeitamos H0")
  )
)

# Exibir a tabela
kable(resultados)%>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necessário


```

Decisão sobre Teste $𝐻0 : 𝛼 + 𝛽 = 1$ contra $𝐻1 : 𝛼 + 𝛽 ≠ 1$:
(@tbl-teste) Como o valor-p é extremamente pequeno, rejeitamos a
hipótese nula $H_0$ indicando que a soma de $\alpha$ e $\beta$ é
significativamente diferente de 1. Isso significa que a hipótese de
retornos constantes à escala não é válida para os dados analisados.

Retornos constantes à escala implicam que, se ambos os insumos (L e K)
aumentarem na mesma proporção, a produção $Y_i$ também aumentará na
mesma proporção. No entanto, dado que a soma de $\alpha$ e $\beta$ é
significativamente diferente de 1, isso sugere que os retornos à escala
não são constantes para este modelo. Dependendo do valor específico da
soma $(\alpha + \beta < 1$ ou $\alpha + \beta > 1)$, os retornos à
escala podem ser decrescentes ou crescentes, respectivamente.

Assim, a soma de $\alpha$ e $\beta$ é 0.08383678, o que está longe de 1,
indicando retornos decrescentes à escala. Isso significa que aumentar
proporcionalmente a força de trabalho e o capital levará a um aumento
menos que proporcional na produção. Em outras palavras, conforme mais
insumos são adicionados, a produtividade marginal desses insumos
diminui, levando a um crescimento menos eficiente da produção.

### Análise dos Resíduos

```{r}
#| tbl-cap: Gráfico de Análise de resíduos 
#| label: tbl-gamma1

library(lmtest)
ggresiduals(fit_gamma )

```

```{r}
fit_gammaa <-bptest(fit_gamma)

# Teste de Durbin-Watson
dw_test_gamma <- dwtest(fit_gamma)
```

```{r}
# Criando a tabela de resultados
test_results <- data.frame(
  Teste = c("Breusch-Pagan", "Durbin-Watson"),
  Estatística = c(2.6679, 2.1338),
  `Valor-p` = c(0.2634, 0.7801),
  Decisão = c(
    ifelse(0.2634 < 0.05, "Rejeitamos H0", "Não rejeitamos H0"),
    ifelse(0.7801 < 0.05, "Rejeitamos H0", "Não rejeitamos H0")
  )
)

# Exibir a tabela usando kable
kable(test_results, caption = "Resultados dos Testes de Breusch-Pagan e Durbin-Watson") %>%
  kable_styling(full_width = F, position = "center")%>%
    column_spec(2, width = "17em")  # Ajuste a largura conforme necessário

```

Com base na análise dos resíduos, incluindo os testes de Breusch-Pagan e
Durbin-Watson, podemos concluir o seguinte sobre o ajuste do modelo de
regressão:

**Homocedasticidade:** - A variância dos resíduos parece ser constante
em toda a faixa dos valores ajustados. Com o teste de Teste de
Breusch-Paga, com um valor-p de 0.2634, não rejeitamos a hipótese nula
de homocedasticidade. Isso significa que não há evidências suficientes
para sugerir a presença de heterocedasticidade nos resíduos do modelo
gamma.

**Normalidade:** - Embora o teste de Shapiro-Wilk sugira que os resíduos
não sigam uma distribuição normal, desconsiderando caudas pesadas tanto
nos extremos inferiores quanto nos superiores, podemos aproximar que os
resíduos estão próximos de uma distribuição normal.

**Independência dos Resíduos:** - Tanto o teste de Durbin-Watson quanto
a inspeção do gráfico de resíduos versus valores ajustados na tabela
@tbl-gamma1 não fornecem evidências significativas para rejeitar a
hipótese nula de ausência de autocorrelação positiva ou negativa nos
resíduos. Assim, parece que os resíduos são independentes entre si, o
que é uma boa indicação de que o modelo está adequadamente ajustado
quanto a essa suposição.

**Linearidade:** - Há um padrão claro nos resíduos plotados em relação
aos valores ajustados, indicando não linearidade entre as variáveis
independentes e dependentes.

## Comparação dos Modelos: Gamma Log-Linear vs. Modelo Normal

```{r,include=FALSE}
# Obter o log-likelihood dos modelos
logLik(fit_gamma)
logLik(fit)

```

```{r,include=FALSE}
# Obter o AIC dos modelos
AIC(fit_gamma)
AIC(fit)

```

```{r,include=FALSE}
# Obter o BIC dos modelos
BIC(fit_gamma)
BIC(fit)

```

```{r}
# Criar um data frame com os dados dos modelos
model_comparison <- data.frame(
  Critério = c("Log-Likelihood", "AIC", "BIC"),
  `Modelo Gamma Log-Linear` = c(-83.07791, 174.1558, 186.0351),
  `Modelo Normal` = c(-59.39108, 126.7822, 138.6614)
)

# Exibir a tabela usando kable
kable(model_comparison, caption = "Comparação dos Modelos Gamma Log-Linear e Normal")%>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necessário

```

Log-Likelihood (Log-Verossimilhança) - **Modelo Gamma Log-Linear**:
-83.07791 - **Modelo Normal**: -59.39108

O valor de log-likelihood mais alto (menos negativo) indica um melhor
ajuste do modelo aos dados. O modelo normal tem um valor de
log-likelihood mais alto, sugerindo que se ajusta melhor aos dados em
comparação com o modelo Gamma log-linear.

Critério de Informação de Akaike (AIC) - **Modelo Gamma Log-Linear**:
174.1558 - **Modelo Normal**: 126.7822

Valores menores de AIC indicam um modelo mais eficiente em termos de
ajuste aos dados com penalização pela complexidade. O modelo normal
apresenta um AIC significativamente menor, indicando que é mais
eficiente e se ajusta melhor aos dados do que o modelo Gamma log-linear.

Critério de Informação de Bayes (BIC) - **Modelo Gamma Log-Linear**:
186.0351 - **Modelo Normal**: 138.6614

O BIC também penaliza a complexidade do modelo e valores menores indicam
um ajuste melhor com menor penalização por complexidade. Novamente, o
modelo normal apresenta um BIC significativamente menor, reforçando que
é mais adequado para os dados em comparação ao modelo Gamma log-linear.

Com base nos critérios de log-likelihood, AIC e BIC, o **modelo normal**
é a melhor escolha. Ele não só se ajusta melhor aos dados (conforme
indicado pelo log-likelihood), mas também é mais eficiente e simples em
termos de complexidade (conforme indicado pelos valores de AIC e BIC).

Portanto, o modelo normal é preferível ao modelo Gamma log-linear para a
análise dos seus dados, oferecendo um melhor equilíbrio entre ajuste e
complexidade.

# Dados Kaggle - análise de clssificação de crédito

## Modelo Logistico

Para este estudo, utilizamos uma base de dados obtida do Kaggle, que
contém informações detalhadas sobre clientes de uma instituição
financeira. O objetivo principal é desenvolver um modelo de machine
learning para classificar o crédito dos clientes em diferentes faixas de
risco, otimizando os processos de decisão e reduzindo esforços manuais.
A base de dados inclui 100.000 observações e 28 variáveis, como idade,
ocupação, renda anual, número de contas bancárias e histórico de
pagamentos.

A análise foca na construção e avaliação de um modelo de **regressão
logística**, adequado para situações em que a variável dependente é
categórica, como a classificação de crédito ("Poor" e "Good"). A
**regressão logística** estima a probabilidade de um evento binário
ocorrer e classifica as observações em categorias. A equação do modelo
logístico é expressa como:

$$log(p / (1 - p)) = β0 + β1 * X_1 + β2 * X_2 + ... + βp * X_p$$

Onde:

-   $p$ é a probabilidade de um cliente ser classificado como "Good"
    (cliente ser um bom pagador).

-   $1-p$ é a probabilidade de um cliente ser classificado como "Poor"
    (cliente possui um histórico problemático).

-   $X_1, X_2, ..., X_p$ são as variáveis independentes (como histórico
    de pagamentos, dívida pendente, etc.)

-   $\beta_0, \beta_1, ..., \beta_p$ são os coeficientes que medem o
    impacto de cada variável independente na probabilidade de ser
    classificado como "Good".

Como parte da análise, será explorado o ajuste do modelo, avaliando os
resíduos para verificar a adequação do modelo.

```{r}
## carregando dados: base teste (Kaggle)
## - os dados são carregados no objeto "dta"
setwd("C:/Users/eliana.cardoso/OneDrive - Fundação Dom Cabral/Documentos/GitHub/Trabalhodemlg")

dta_teste = read.csv('_dta/test.csv') #credit_scoring
dta_treino = read.csv('_dta/train.csv')

# dim(dta_treino)

```

```{r}
# Limpeza da base
# Selecionando variáveis necessárias
dta <- subset(dta_treino, select = c(Credit_Score,Credit_Mix, Outstanding_Debt, Payment_of_Min_Amount, Changed_Credit_Limit))

# Checando valores ausentes
valores_faltantes <-data.frame(sort(colSums(is.na(dta)), decreasing = TRUE))

# Preparando a variável dependente
dta = dta %>% dplyr::filter(Credit_Score != "Standard")

dta$Credit_Score <- factor(dta$Credit_Score, levels = c('Good', 'Poor'))

# Preparando preditores contínuos
dta$Outstanding_Debt <- as.numeric(str_extract(dta$Outstanding_Debt, "[0-9.]+"))
dta <- dta[which(dta$Changed_Credit_Limit != "_"), ]
dta$Changed_Credit_Limit <- as.numeric(dta$Changed_Credit_Limit)

# Preparando preditores categóricos
dta <- dta[which(dta$Credit_Mix != "_"), ]
dta$Credit_Mix <- factor(dta$Credit_Mix, levels = c('Good', 'Standard', 'Bad'))
dta <- dta[which(dta$Payment_of_Min_Amount != "NM"), ]
dta$Payment_of_Min_Amount <- factor(dta$Payment_of_Min_Amount, levels = c('No', 'Yes'))

# Análise descritiva
summary_dta3<-summary(dta)



```

```{r}

summary_table <- data.frame(
  Variável = c("Credit_Score", "Credit_Mix", "Outstanding_Debt", "Payment_of_Min_Amount", "Changed_Credit_Limit"),
  Estatística = c(
    "Good: 12192, Poor: 19884", 
    "Good: 13518, Standard: 8509, Bad: 10049", 
    "Min.: 0.23, 1st Qu.: 702.54, Median: 1360.45, Mean: 1593.26, 3rd Qu.: 2258.30, Max.: 4998.07",
    "No: 14432, Yes: 17644", 
    "Min.: -6.480, 1st Qu.: 4.570, Median: 8.560, Mean: 9.573, 3rd Qu.: 13.130, Max.: 35.820"
  )
)

# Exibir a tabela usando kable
kable(summary_table, caption = "Resumo Descritivo das Variáveis") %>%
  kable_styling(full_width = F, position = "center") %>% 
    column_spec(2, width = "17em")  # Ajuste a largura conforme necessário

```

A análise descritiva das variáveis na base de dados dta revela que, dos
32.076 clientes analisados, 12.192 foram classificados como "Good" e
19.884 como "Poor", indicando que a maioria dos clientes tem uma
classificação de crédito ruim. A variável Credit_Mix mostra que a
maioria dos clientes tem uma mistura de crédito considerada "Good",
seguida por "Standard" e "Bad", o que pode influenciar a classificação
final de risco. Em relação à dívida pendente, os valores variam
significativamente, com uma mediana de 1.360,45 e uma média de 1.593,26,
sugerindo que alguns clientes têm dívidas elevadas, o que pode aumentar
o risco de crédito. Quanto ao pagamento do valor mínimo, 17.644 clientes
o fizeram, enquanto 14.432 não, indicando que pagar apenas o valor
mínimo pode ser um indicador de problemas financeiros. A variável
Changed_Credit_Limit mostra variações entre -6,48 e 35,82, com uma
mediana de 8,56, sugerindo mudanças no comportamento de crédito ao longo
do tempo. Essas observações iniciais são fundamentais para a construção
do modelo de regressão logística e devem orientar a escolha de variáveis
e a interpretação dos resultados.

```{r}
# Análise associativa preliminar
# Boxplot para Outstanding_Debt por Credit_Score
boxplot(Outstanding_Debt ~ Credit_Score, data = dta,
        main = "Distribuição da Dívida Pendente por Classificação de Crédito")
# Boxplot para Changed_Credit_Limit por Credit_Score
boxplot(Changed_Credit_Limit ~ Credit_Score, data = dta,
        main = "Variação no Limite de Crédito por Classificação de Crédito")
```

```{r}

# Executa os testes qui-quadrado
test1 <- chisq.test(x = dta$Credit_Mix, y = dta$Credit_Score)
test2 <- chisq.test(x = dta$Payment_of_Min_Amount, y = dta$Credit_Score)

chi_square_results <- data.frame(
  Teste = c("Credit_Mix vs Credit_Score", "Payment_of_Min_Amount vs Credit_Score"),
  Estatística = c(14606, 14578),
  `Graus de Liberdade` = c(2, 1),
  `Valor-p` = c("< 2.2e-16", "< 2.2e-16"),
  Decisão = c(
    "Rejeitamos H0",
    "Rejeitamos H0"
  )
)

# Exibir a tabela usando kable
kable(chi_square_results, caption = "Resultados dos Testes Qui-Quadrado") %>%
  kable_styling(full_width = F, position = "center")

```

A análise associativa preliminar entre as variáveis do estudo revela
insights importantes sobre os padrões de crédito dos clientes. Através
dos boxplots, observa-se que a dívida pendente (Outstanding_Debt) tende
a ser maior entre os clientes com uma classificação de crédito "Poor" em
comparação com aqueles classificados como "Good". Isso sugere que
clientes com maiores dívidas são mais propensos a terem uma
classificação de crédito inferior. Além disso, as mudanças no limite de
crédito (Changed_Credit_Limit) também variam significativamente entre as
classificações de crédito, com clientes de crédito "Poor" exibindo maior
variação, o que pode indicar instabilidade financeira.

As análises de qui-quadrado entre as variáveis categóricas reforçam
essas observações. O teste de associação entre a mistura de crédito
(Credit_Mix) e a classificação de crédito (Credit_Score) resultou em um
valor de X² de 14.606 com um p-valor extremamente significativo (\<
2,2e-16), indicando uma forte associação entre essas variáveis. Isso
sugere que a composição do crédito do cliente tem uma influência
considerável sobre sua classificação de crédito. De forma similar, o
teste de qui-quadrado entre o pagamento do valor mínimo
(Payment_of_Min_Amount) e a classificação de crédito também mostrou uma
associação significativa (X² = 14.578, p \< 2,2e-16), sugerindo que
clientes que não pagam o valor mínimo regularmente têm maior
probabilidade de serem classificados como "Poor". Esses resultados
preliminares fornecem evidências robustas de que variáveis financeiras e
comportamentais desempenham um papel crucial na determinação do risco de
crédito, justificando sua inclusão no modelo de regressão logística
subsequente.

### Modelo logístico ajustado

O modelo de regressão logística ajustado para classificar o crédito dos
clientes foi desenvolvido utilizando A função de link utilizada foi a
logit, adequada para a análise de variáveis binárias como o
Credit_Score.

Além disso, para a construção do modelo foram utilizadas as seguintes
variáveis:

```{r}
# Ajuste do modelo de regressão logística
out <- glm(Credit_Score ~ Credit_Mix + Outstanding_Debt + Payment_of_Min_Amount + Changed_Credit_Limit, 
           family = binomial(link = logit), data = dta)

tabela<-as.data.frame(coef(summary(out)))
tabela <- cbind(Covariavel = rownames(tabela), tabela)

# Criação da tabela com os resultados
tabela_formatada <- data.frame(
  Variável = tabela$Covariavel,
  Estimacao = tabela$Estimate,
  ErroPadrao = tabela$`Std. Error`,
  Pvalor = ifelse(tabela$`Pr(>|z|)` < 0.05, "< 0.05", format(tabela$`Pr(>|z|)`, digits = 4, nsmall = 4))
)

# Exibindo a tabela
kable(tabela_formatada, caption = "Resultados do Modelo de Regressão Logística") %>%
  kable_styling(full_width = F, position = "center")


```

Os coeficientes do modelo são significativos, com valores de p
inferiores a 0,05 para todas as variáveis, indicando que elas têm uma
contribuição estatisticamente significativa na previsão da classificação
de crédito.

Aqui, o intercepto é −1.485, enquanto os coeficientes para as variáveis
Credit_MixStandard e Credit_MixBad são positivos e relativamente altos,
o que sugere um efeito significativo na probabilidade de um cliente ser
classificado como "Good". Outstanding_Debt e Payment_of_Min_AmountYes
também apresentam coeficientes positivos, refletindo seu impacto
positivo na probabilidade de uma boa classificação de crédito. O
coeficiente de Changed_Credit_Limit é negativo, indicando que um aumento
no limite de crédito alterado está associado a uma menor probabilidade
de classificação positiva.

O modelo apresenta um desvio nulo de 42604 e um desvio residual de
24833. A redução no desvio residual em relação ao desvio nulo indica que
o modelo com as variáveis independentes tem um ajuste significativamente
melhor do que o modelo nulo. Em outras palavras, o modelo ajustado reduz
a discrepância entre os valores previstos e os observados de forma
significativa.

Quanto ao AIC, vale salientar que O AIC é uma métrica que ajuda a
avaliar a qualidade do ajuste do modelo, levando em consideração tanto a
complexidade quanto a adequação ao conjunto de dados. A principal função
do AIC é penalizar modelos mais complexos, que possuem um maior número
de parâmetros, para evitar o ajuste excessivo aos dados (overfitting).No
caso, o AIC obtido foi de 24845. Para determinar se este valor indica um
bom ajuste do modelo, é necessário compará-lo com o AIC de outros
modelos que você pode ter testado.

Para o modelo ajustado foi calculado também a razão de chances:

```{r}
# Calcular razões de chances (odds ratios)
OR <- exp(coef(out))

or_table <- data.frame(
  Odds_Ratio = round(OR, 3)
)

# Imprimir a tabela com kable
kable(or_table, caption = "Razões de Chances (Odds Ratios) do Modelo de Regressão Logística")

```

As razões de chances (odds ratios) para o modelo de regressão logística
ajustado fornecem uma visão sobre como cada variável preditora afeta a
probabilidade de uma boa classificação de crédito. As variáveis
"Credit_MixStandard" e "Credit_MixBad" têm odds ratios de
aproximadamente 2.75 e 10.43, respectivamente, indicando que os
indivíduos com essas classificações de crédito têm odds
significativamente maiores de obter uma boa classificação em comparação
com a categoria de referência. O valor da dívida pendente
("Outstanding_Debt") tem um odds ratio próximo de 1, sugerindo que sua
influência nas odds é mínima. Por outro lado, pagar o valor mínimo
requerido ("Payment_of_Min_AmountYes") aumenta as odds de uma boa
classificação de crédito em cerca de 4.15 vezes. O limite de crédito
alterado ("Changed_Credit_Limit") tem um odds ratio de 0.98, indicando
uma leve diminuição nas odds de uma boa classificação com cada unidade
adicional de alteração no limite de crédito. Esses resultados ajudam a
entender a importância relativa de cada variável na previsão da
classificação de crédito.

Tentamos ajustar o modelo logistico, re-escalando Outstanding Debt:

```{r}
dta$Outstanding_Debt_scaled = dta$Outstanding_Debt/100

# estimação
out_reescalado = glm(Credit_Score ~ 
            Credit_Mix + Outstanding_Debt_scaled +
            Payment_of_Min_Amount + Changed_Credit_Limit, 
            family = binomial(link = logit),
            data = dta)



tabela<-as.data.frame(coef(summary(out_reescalado)))
tabela <- cbind(Covariavel = rownames(tabela), tabela)

# Criação da tabela com os resultados
tabela_formatada <- data.frame(
  Variável = tabela$Covariavel,
  Estimacao = tabela$Estimate,
  ErroPadrao = tabela$`Std. Error`,
 Pvalor = ifelse(tabela$`Pr(>|z|)` < 0.05, "< 0.05", format(tabela$`Pr(>|z|)`, digits = 4, nsmall = 4)))

tabela_formatada$Pvalor <- format(tabela_formatada$Pvalor, scientific = TRUE, digits = 5)

# Exibindo a tabela
kable(tabela_formatada, caption = "Resultados do Modelo de Regressão Logística") %>%
  kable_styling(full_width = F, position = "center")




```

Visando verificar se é possível melhorar o modelo logístico ajustado, a
variável Outstanding_Debt foi recalibrada. No modelo anterior, o
coeficiente para Outstanding_Debt era muito pequeno (6.567e-04),
enquanto no modelo ajustado com a variável escalada
(Outstanding_Debt_scaled), a estimativa do coeficiente foi
significativamente maior (0.065672), indicando um efeito mais expressivo
da variável escalada. No entanto, apesar de a escalagem ter melhorado a
interpretação dos coeficientes, os desvios nulo e residual, assim como o
AIC, permaneceram inalterados (o AIC é 24845 para ambos os modelos).
Isso sugere que, embora a escalagem tenha proporcionado coeficientes
mais interpretáveis, ela não resultou em uma melhoria no ajuste global
do modelo.

### Análise dos Resíduos

A análise dos resíduos é crucial para avaliar se o modelo logístico está
bem ajustado. Resíduos bem comportados, ou seja, sem padrões claros e
distribuídos de forma aleatória, indicam que o modelo é adequado. Se
houver padrões nos resíduos, isso pode sugerir que o modelo não está
capturando toda a variabilidade dos dados, podendo haver variáveis
importantes faltantes ou problemas de especificação do modelo

```{r}

ggresiduals(out)

```

```{r,include=FALSE}

bptest(out)

# Teste de Durbin-Watson
dw_test2 <- dwtest(out)

```

```{r}
# Carregar pacotes necessários
library(knitr)
library(kableExtra)

# Resultados dos testes
bp_test <- c("BP = 3931.9", "df = 5", "p-value < 2.2e-16")
dw_test <- c("DW = 0.65232", "p-value < 2.2e-16")

# Criar data frame para os resultados
test_results <- data.frame(
  Teste = c("Breusch-Pagan", "Durbin-Watson"),
  Estatistica = c("BP = 3931.9", "DW = 0.65232"),
  Graus_de_Liberdade = c("df = 5", NA),
  P_valor = c("p-value < 2.2e-16", "p-value < 2.2e-16")
)

# Exibir a tabela usando kable
kable(test_results, caption = "Resultados dos Testes Breusch-Pagan e Durbin-Watson") %>%
  kable_styling(full_width = F, position = "center")

```

Com base nos resultados obtidos via Teste de Breusch-Pagan e Teste de
Durbin-Watson, podemos concluir o seguinte sobre o ajuste do modelo de
regressão logística:

**Homocedasticidade:** - O Teste de Breusch-Pagan resultou em um valor
de BP = 3931.9 com um valor-p \< 2.2e-16. Esse valor-p extremamente
baixo indica que rejeitamos a hipótese nula de homocedasticidade. Em
outras palavras, há evidências significativas de heterocedasticidade nos
resíduos do modelo. Isso sugere que a variância dos resíduos não é
constante ao longo dos valores preditores, o que pode indicar que o
modelo não está capturando completamente a variabilidade dos dados.

**Independência dos Resíduos:** - O Teste de Durbin-Watson forneceu um
valor de DW = 0.65232 com um valor-p \< 2.2e-16, indicando uma forte
presença de autocorrelação positiva nos resíduos. Isso sugere que os
resíduos não são independentes entre si, o que pode indicar que o modelo
não está capturando todos os padrões nos dados ou que há uma estrutura
de dependência não modelada.

A inspeção do gráfico de resíduos versus valores ajustados também pode
revelar padrões adicionais que confirmem a presença de autocorrelação.

**Linearidade:** - Há um padrão claro nos resíduos plotados em relação
aos valores ajustados, indicando não linearidade entre as variáveis
independentes e dependentes.

Desse modo, os resultados sugerem que o modelo enfrenta problemas de
heterocedasticidade e autocorrelação positiva dos resíduos, o que pode
impactar a precisão e a validade do modelo.

### Análise do VIF (Variance Inflation Factor)

O VIF (Fator de Inflação da Variância) é uma medida importante para
identificar a presença de multicolinearidade entre os preditores em um
modelo de regressão. Valores elevados de VIF sugerem que um preditor
está altamente correlacionado com outros preditores no modelo, o que
pode inflacionar os erros padrão das estimativas dos coeficientes e
dificultar a identificação da real significância das variáveis.

```{r}
# Resultados do VIF
vif_results <- data.frame(
  Preditor = c("Credit_Mix", "Outstanding_Debt", "Payment_of_Min_Amount", "Changed_Credit_Limit"),
  GVIF = c(5.405144, 1.626080, 5.496045, 1.558789),
  Df = c(2, 1, 1, 1),
  'Ajuste do GVIF' = c(1.524761, 1.275178, 2.344365, 1.248515)
)

# Exibir a tabela usando kable
kable(vif_results, caption = "VIF dos Preditores") %>%
  kable_styling(full_width = F, position = "center")

```

```{r}
# Resultados dos erros padrão dos coeficientes
errors_std_results <- data.frame(
  Coeficiente = c("Intercept", "Credit_MixStandard", "Credit_MixBad", 
                  "Outstanding_Debt", "Payment_of_Min_AmountYes", 
                  "Changed_Credit_Limit"),
  Erro_Padrão = c(0.0361200, 0.0701266, 0.1036433, 
                  0.0000294, 0.0804651, 0.0036734)
)

# Exibir a tabela usando kable
kable(errors_std_results, caption = "Erros Padrão dos Coeficientes") %>%
  kable_styling(full_width = F, position = "center")
```

No modelo analisado, observamos que as variáveis Credit_Mix e
Payment_of_Min_Amount têm VIFs relativamente altos, com valores de 5.41
e 5.50, respectivamente. Esses valores indicam uma alta colinearidade
com outras variáveis do modelo. Isso é corroborado pelos erros padrão
dos coeficientes: Credit_MixStandard e Credit_MixBad apresentam erros
padrão elevados, especialmente Credit_MixBad com um erro padrão de
0.1036, o que sugere que as estimativas dos coeficientes para estas
variáveis são menos precisas e podem ser afetadas pela
multicolinearidade.

Em contraste, Outstanding_Debt e Changed_Credit_Limit têm VIFs baixos,
de 1.63 e 1.56, respectivamente. Isso sugere que estas variáveis têm
baixa colinearidade com outras variáveis do modelo. O erro padrão para
Outstanding_Debt é extremamente pequeno (aproximadamente 0.0000),
indicando uma estimativa muito precisa para o coeficiente desta
variável. Da mesma forma, Changed_Credit_Limit tem um erro padrão muito
pequeno (0.0037), o que também sugere uma estimativa precisa para o
coeficiente desta variável.

Por outro lado, o erro padrão para Payment_of_Min_AmountYes é
relativamente grande (0.0805), o que pode refletir a alta
multicolinearidade observada pelo VIF elevado para
Payment_of_Min_Amount. Isso indica que a estimativa do coeficiente para
esta variável pode ser menos confiável.

Em resumo, a alta multicolinearidade identificada para Credit_Mix e
Payment_of_Min_Amount está associada a erros padrão mais altos para
essas variáveis, o que sugere que as estimativas dos coeficientes podem
ser imprecisas. Em contraste, variáveis com VIFs baixos como
Outstanding_Debt e Changed_Credit_Limit apresentam erros padrão menores
e estimativas mais confiáveis. Considerar a remoção ou ajuste das
variáveis com alta colinearidade pode melhorar a precisão e robustez do
modelo.
